{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Use \"prodigyEnv\" conda environment for this notebook.\n",
    "\n",
    "To set up Prodigy environment, download the wheel file from the Prodigy email (which you receive after purchasing a license). \n",
    "\n",
    "Then run `pip install ./prodigy*.whl`\n",
    "\n",
    "Instructions: https://prodi.gy/docs/install\n",
    "\n",
    "Database is stored at /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from prodigy.components.db import connect\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_mean(df, by, column, rot=0):\n",
    "    # use dict comprehension to create new dataframe from the iterable groupby object\n",
    "    # each group name becomes a column in the new dataframe\n",
    "    df2 = pd.DataFrame({col:vals[column] for col, vals in df.groupby(by)})\n",
    "    # find and sort the median values in this new dataframe\n",
    "    means = df2.mean().sort_values()\n",
    "    # use the columns in the dataframe, ordered sorted by median value\n",
    "    # return axes so changes can be made outside the function\n",
    "#     return df2[meds.index].boxplot(rot=rot, return_type=\"axes\")\n",
    "    return means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bc-reddit-posts',\n",
       " 'bc-reddit-comments',\n",
       " 'bc-twitter-posts',\n",
       " 'bc-twitter-replies',\n",
       " 'discourse-reddit-posts',\n",
       " 'discourse-reddit-comments',\n",
       " 'discourse-webmd-reviews']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = connect()\n",
    "\n",
    "db.datasets # This will list all of your prodigy databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.drop_dataset('discourse-reddit-posts')  # Only do this if you want to delete all your annotations!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Explore REDDIT posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-reddit-posts')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "46 \t SHARING EXPERIENCES\n",
      "27 \t NONE\n",
      "25 \t SHARING DECISION-MAKING PROCESSES\n",
      "21 \t SEEKING INFORMATION\n",
      "14 \t SHARING NEGATIVE EMOTIONS\n",
      "10 \t SHARING FUTURE PLANS\n",
      "9 \t SEEKING EXPERIENCES\n",
      "7 \t SHARING PERSONAL BACKGROUND\n",
      "6 \t SHARING OPINIONS AND PREFERENCES\n",
      "5 \t SEEKING ADVICE\n",
      "3 \t SEEKING NORMALITY\n",
      "2 \t PROVIDING INFORMATION\n",
      "2 \t SHARING SECONDHAND EXPERIENCES\n",
      "2 \t SHARING POSITIVE EMOTIONS\n",
      "1 \t PROVIDING ADVICE\n",
      "1 \t META DISCUSSION\n",
      "1 \t SEEKING EMOTIONAL SUPPORT\n",
      "1 \t PROVIDING NORMALITY\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "18 \t SHARING EXPERIENCES\n",
      "7 \t SHARING DECISION-MAKING PROCESSES\n",
      "7 \t SEEKING INFORMATION\n",
      "4 \t SHARING PERSONAL BACKGROUND\n",
      "2 \t SHARING FUTURE PLANS\n",
      "2 \t SHARING NEGATIVE EMOTIONS\n",
      "2 \t SEEKING ADVICE\n",
      "1 \t PROVIDING ADVICE\n",
      "1 \t PROVIDING INFORMATION\n",
      "1 \t SEEKING EXPERIENCES\n",
      "1 \t SEEKING EMOTIONAL SUPPORT\n",
      "1 \t SEEKING NORMALITY\n",
      "1 \t PROVIDING NORMALITY\n",
      "1 \t SHARING OPINIONS AND PREFERENCES\n",
      "\n",
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "14 \t SHARING EXPERIENCES\n",
      "11 \t SHARING DECISION-MAKING PROCESSES\n",
      "7 \t SEEKING EXPERIENCES\n",
      "7 \t SEEKING INFORMATION\n",
      "6 \t SHARING FUTURE PLANS\n",
      "4 \t SHARING NEGATIVE EMOTIONS\n",
      "3 \t SHARING PERSONAL BACKGROUND\n",
      "2 \t SHARING SECONDHAND EXPERIENCES\n",
      "2 \t SEEKING ADVICE\n",
      "2 \t SHARING OPINIONS AND PREFERENCES\n",
      "1 \t META DISCUSSION\n",
      "1 \t PROVIDING INFORMATION\n",
      "1 \t SHARING POSITIVE EMOTIONS\n",
      "\n",
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "14 \t SHARING EXPERIENCES\n",
      "8 \t SHARING NEGATIVE EMOTIONS\n",
      "7 \t SHARING DECISION-MAKING PROCESSES\n",
      "7 \t SEEKING INFORMATION\n",
      "3 \t SHARING OPINIONS AND PREFERENCES\n",
      "2 \t SHARING FUTURE PLANS\n",
      "2 \t SEEKING NORMALITY\n",
      "1 \t SHARING POSITIVE EMOTIONS\n",
      "1 \t SEEKING ADVICE\n",
      "1 \t SEEKING EXPERIENCES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "31.5% \t SHARING EXPERIENCES\n",
      "18.5% \t NONE\n",
      "17.1% \t SHARING DECISION-MAKING PROCESSES\n",
      "14.4% \t SEEKING INFORMATION\n",
      "9.6% \t SHARING NEGATIVE EMOTIONS\n",
      "6.8% \t SHARING FUTURE PLANS\n",
      "6.2% \t SEEKING EXPERIENCES\n",
      "4.8% \t SHARING PERSONAL BACKGROUND\n",
      "4.1% \t SHARING OPINIONS AND PREFERENCES\n",
      "3.4% \t SEEKING ADVICE\n",
      "2.1% \t SEEKING NORMALITY\n",
      "1.4% \t PROVIDING INFORMATION\n",
      "1.4% \t SHARING SECONDHAND EXPERIENCES\n",
      "1.4% \t SHARING POSITIVE EMOTIONS\n",
      "0.7% \t PROVIDING ADVICE\n",
      "0.7% \t META DISCUSSION\n",
      "0.7% \t SEEKING EMOTIONAL SUPPORT\n",
      "0.7% \t PROVIDING NORMALITY\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "SHARING DECISION-MAKING PROCESSES\n",
      "------------------------------------------\n",
      "\n",
      "Since I've been so stressed out, I decided that since I had forgot a few pills, I would go off the pill for a month or two and let my body rest during the Christmas university break.\n",
      "It lasted for a few weeks but I figured it was because of the change .\n",
      "It is honestly the best choice for me.\n",
      "I thought I would be fine since I was on the depo so long beforehand, and didn't even realize this could possibly be a symptom of the implant.\n",
      "This lasted for MONTHS, so I read somewhere online that vitamin e and zinc help with this, and it did stop the bleeding for a couple weeks, but I just started spotting again today.\n",
      "I'm getting my IUD placed during my cycle, and debating whether I should wear my cup, a flex disc, or a pad.\n",
      "But I have been reluctant to go back on the meds because I am not ok with the side effects.\n",
      "I'm now doing a 5 month Accutane course as suggested by my dermatologist because I'm still breaking out consistently with large cysts.\n",
      "TL;DR: Can't stay on BC pills, bad acid reflux, want to stick with pills.\n",
      "She also said I could consider Skyla but with it only being 3 years, Kyleena would be better.\n",
      "I'm wondering if this is a Mirena crash or just really bad PMS since my period is due Monday.\n",
      "I am taking the pill continuously to not have a period but this spotting is pretty much a period.\n",
      "my nexplanon implant is the only thing atm that works, but the side effects are killing me.\n",
      "I took a pregnancy test this morning which was negative, but these symptoms are freaking me out a little.\n",
      "So I've been on the combination pill for like a year and a half and after having some bloodwork done I've discovered that I have high cholesterol.\n",
      "After looking at all my options (and waiting for depo to wear off) I went ahead with Kyleena.\n",
      "I asked if that was possible and in the end she was just like ok worst case the implant doesn’t work and then what?\n",
      "And seeing as I wasn’t on it long I’m assuming my libido should be back to normal in a few days?\n",
      "Probably started before then but because I wasn’t dating I didn’t notice.\n",
      "I'm thinking about counting it as a missed pill and taking another one just to cover all my bases.\n",
      "I think I may have had a cyst rupture, I've had this happened before and it has been that painful.\n",
      "I’ve been on heavily hormonal birth control since literally puberty and am afraid I’m unaware of how much it may have changed me and I want to know what it feels like to be a young woman without it.\n",
      "I'm sure this has been asked before but after scouring the search results for a while, I decided it was best to just ask again.\n",
      "I'm considering either the patch or the ring, but I would love to get Mirena again, but I'm petrified of having that experience again...\n",
      "As most people who are planning on getting an IUD, I started prepping myself by reading every single personal experience and article on the internet.\n"
     ]
    }
   ],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'SHARING DECISION-MAKING PROCESSES':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Explore REDDIT comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-reddit-comments')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "23 \t SHARING EXPERIENCES\n",
      "20 \t SHARING INFORMATION\n",
      "17 \t NONE\n",
      "9 \t SHARING ADVICE\n",
      "7 \t SHARING OPINIONS AND PREFERENCES\n",
      "4 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "4 \t SEEKING EXPERIENCES\n",
      "4 \t META DISCUSSION\n",
      "3 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "3 \t SHARING EMOTIONAL SUPPORT\n",
      "3 \t SHARING FUTURE PLANS\n",
      "3 \t SHARING SECONDHAND EXPERIENCES\n",
      "3 \t SHARING NORMALITY\n",
      "2 \t SEEKING INFORMATION\n",
      "1 \t SHARING POSITIVE EMOTIONS\n",
      "1 \t SHARING NEGATIVE EMOTIONS\n",
      "1 \t SHARING PERSONAL BACKGROUND\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "7 \t SHARING INFORMATION\n",
      "6 \t SHARING EXPERIENCES\n",
      "3 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "2 \t SEEKING EXPERIENCES\n",
      "2 \t META DISCUSSION\n",
      "2 \t SHARING SECONDHAND EXPERIENCES\n",
      "1 \t SHARING OPINIONS AND PREFERENCES\n",
      "1 \t SHARING ADVICE\n",
      "1 \t SHARING FUTURE PLANS\n",
      "1 \t SEEKING INFORMATION\n",
      "1 \t SHARING NORMALITY\n",
      "1 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "\n",
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "8 \t SHARING INFORMATION\n",
      "8 \t SHARING EXPERIENCES\n",
      "5 \t SHARING OPINIONS AND PREFERENCES\n",
      "2 \t SEEKING EXPERIENCES\n",
      "2 \t SHARING FUTURE PLANS\n",
      "2 \t META DISCUSSION\n",
      "1 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "1 \t SHARING ADVICE\n",
      "1 \t SHARING SECONDHAND EXPERIENCES\n",
      "1 \t SHARING EMOTIONAL SUPPORT\n",
      "1 \t SHARING PERSONAL BACKGROUND\n",
      "1 \t SHARING NORMALITY\n",
      "\n",
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "9 \t SHARING EXPERIENCES\n",
      "7 \t SHARING ADVICE\n",
      "5 \t SHARING INFORMATION\n",
      "2 \t SHARING EMOTIONAL SUPPORT\n",
      "1 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "1 \t SHARING OPINIONS AND PREFERENCES\n",
      "1 \t SHARING POSITIVE EMOTIONS\n",
      "1 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "1 \t SHARING NORMALITY\n",
      "1 \t SHARING NEGATIVE EMOTIONS\n",
      "1 \t SEEKING INFORMATION\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "23.0% \t SHARING EXPERIENCES\n",
      "20.0% \t SHARING INFORMATION\n",
      "17.0% \t NONE\n",
      "9.0% \t SHARING ADVICE\n",
      "7.0% \t SHARING OPINIONS AND PREFERENCES\n",
      "4.0% \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "4.0% \t SEEKING EXPERIENCES\n",
      "4.0% \t META DISCUSSION\n",
      "3.0% \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "3.0% \t SHARING EMOTIONAL SUPPORT\n",
      "3.0% \t SHARING FUTURE PLANS\n",
      "3.0% \t SHARING SECONDHAND EXPERIENCES\n",
      "3.0% \t SHARING NORMALITY\n",
      "2.0% \t SEEKING INFORMATION\n",
      "1.0% \t SHARING POSITIVE EMOTIONS\n",
      "1.0% \t SHARING NEGATIVE EMOTIONS\n",
      "1.0% \t SHARING PERSONAL BACKGROUND\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "------------------------------------------\n",
      "\n",
      "I expect they can, if you don't have insurance coverage and are paying for it yourself I don't know why they would care where you currently reside.\n",
      "That just sounds like ovulation to me...\n",
      "Eek, no! Sounds like it wasn’t placed correctly.\n",
      "I don't really know what I'm talking about, but it could be possible that she had implanon, and got a nexplanon put in instead?\n"
     ]
    }
   ],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'SHARING CAUSAL REASONING / HYPOTHESIZING':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Explore TWITTER posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-twitter-posts')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "38 \t providing information (educational)\n",
      "38 \t narrating personal experiences\n",
      "33 \t NONE\n",
      "29 \t other discourse\n",
      "13 \t humor\n",
      "11 \t seeking information (educational)\n",
      "11 \t negative self-disclosure\n",
      "9 \t seeking experiences\n",
      "8 \t politics\n",
      "7 \t providing other experiences\n",
      "5 \t positive self-disclosure\n",
      "5 \t weighing options\n",
      "4 \t providing information (advice)\n",
      "1 \t providing personal experiences\n",
      "1 \t seeking information (advice)\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "21 \t providing information (educational)\n",
      "14 \t other discourse\n",
      "9 \t humor\n",
      "3 \t seeking information (educational)\n",
      "3 \t narrating personal experiences\n",
      "1 \t politics\n",
      "1 \t seeking experiences\n",
      "1 \t providing other experiences\n",
      "1 \t providing information (advice)\n",
      "\n",
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "25 \t narrating personal experiences\n",
      "9 \t providing information (educational)\n",
      "8 \t negative self-disclosure\n",
      "7 \t seeking experiences\n",
      "6 \t providing other experiences\n",
      "5 \t seeking information (educational)\n",
      "2 \t positive self-disclosure\n",
      "2 \t politics\n",
      "2 \t other discourse\n",
      "1 \t providing information (advice)\n",
      "1 \t humor\n",
      "1 \t seeking information (advice)\n",
      "1 \t weighing options\n",
      "\n",
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "13 \t other discourse\n",
      "10 \t narrating personal experiences\n",
      "8 \t providing information (educational)\n",
      "5 \t politics\n",
      "4 \t weighing options\n",
      "3 \t seeking information (educational)\n",
      "3 \t negative self-disclosure\n",
      "3 \t humor\n",
      "3 \t positive self-disclosure\n",
      "2 \t providing information (advice)\n",
      "1 \t providing personal experiences\n",
      "1 \t seeking experiences\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "19.0% \t providing information (educational)\n",
      "19.0% \t narrating personal experiences\n",
      "16.5% \t NONE\n",
      "14.5% \t other discourse\n",
      "6.5% \t humor\n",
      "5.5% \t seeking information (educational)\n",
      "5.5% \t negative self-disclosure\n",
      "4.5% \t seeking experiences\n",
      "4.0% \t politics\n",
      "3.5% \t providing other experiences\n",
      "2.5% \t positive self-disclosure\n",
      "2.5% \t weighing options\n",
      "2.0% \t providing information (advice)\n",
      "0.5% \t providing personal experiences\n",
      "0.5% \t seeking information (advice)\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "providing other experiences\n",
      "------------------------------------------\n",
      "\n",
      "Mom solves daughter’s mystery illness:\n",
      "Woman forced young girl to get birth control implant in her arm, police say https://t.co/YTq9CvSdI9\n",
      "I understand the pill causes negative affects on some women but it did amazing things for me.\n",
      "My wife just got a birth control implant that has no hormones and will last over 10 years because her boyfriend was tired of pulling out.\n",
      "#News Update: Contraceptive Implant Gets Stuck In Woman And Doctors Still Can't Find It https://t.co/Bhwb1eh2Fe\n",
      "Nexplanon has been good for me so far, seen ppl say they hate it\n",
      "Woman has contraceptive implant 'lost' in her arm for two years - now she needs surgery https://t.co/5LdQtqf5uP\n"
     ]
    }
   ],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'providing other experiences':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Explore Twitter REPLIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-twitter-replies')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "72 \t narrating personal experiences\n",
      "38 \t NONE\n",
      "31 \t providing information (educational)\n",
      "21 \t other discourse\n",
      "10 \t weighing options\n",
      "9 \t providing information (advice)\n",
      "8 \t politics\n",
      "8 \t seeking experiences\n",
      "7 \t humor\n",
      "7 \t providing other experiences\n",
      "4 \t negative self-disclosure\n",
      "3 \t seeking information (educational)\n",
      "3 \t providing personal experiences\n",
      "2 \t providing emotional support\n",
      "1 \t seeking information (advice)\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "15 \t other discourse\n",
      "13 \t providing information (educational)\n",
      "6 \t humor\n",
      "5 \t narrating personal experiences\n",
      "3 \t politics\n",
      "2 \t providing personal experiences\n",
      "2 \t seeking experiences\n",
      "1 \t negative self-disclosure\n",
      "1 \t providing information (advice)\n",
      "1 \t seeking information (educational)\n",
      "\n",
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "37 \t narrating personal experiences\n",
      "8 \t providing information (educational)\n",
      "5 \t providing information (advice)\n",
      "4 \t weighing options\n",
      "3 \t negative self-disclosure\n",
      "3 \t providing other experiences\n",
      "3 \t seeking experiences\n",
      "2 \t other discourse\n",
      "1 \t providing personal experiences\n",
      "1 \t providing emotional support\n",
      "1 \t seeking information (educational)\n",
      "\n",
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "30 \t narrating personal experiences\n",
      "10 \t providing information (educational)\n",
      "6 \t weighing options\n",
      "5 \t politics\n",
      "4 \t other discourse\n",
      "4 \t providing other experiences\n",
      "3 \t providing information (advice)\n",
      "3 \t seeking experiences\n",
      "1 \t seeking information (advice)\n",
      "1 \t seeking information (educational)\n",
      "1 \t providing emotional support\n",
      "1 \t humor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "36.0% \t narrating personal experiences\n",
      "19.0% \t NONE\n",
      "15.5% \t providing information (educational)\n",
      "10.5% \t other discourse\n",
      "5.0% \t weighing options\n",
      "4.5% \t providing information (advice)\n",
      "4.0% \t politics\n",
      "4.0% \t seeking experiences\n",
      "3.5% \t humor\n",
      "3.5% \t providing other experiences\n",
      "2.0% \t negative self-disclosure\n",
      "1.5% \t seeking information (educational)\n",
      "1.5% \t providing personal experiences\n",
      "1.0% \t providing emotional support\n",
      "0.5% \t seeking information (advice)\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'rant':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# Explore WebMD reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-webmd-reviews')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "75 \t SHARING EXPERIENCES\n",
      "22 \t SHARING OPINIONS AND PREFERENCES\n",
      "7 \t SHARING PERSONAL BACKGROUND\n",
      "6 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "6 \t SHARING FUTURE PLANS\n",
      "3 \t SHARING NEGATIVE EMOTIONS\n",
      "3 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "2 \t NONE\n",
      "2 \t META DISCUSSION\n",
      "1 \t SHARING INFORMATION\n",
      "1 \t SHARING POSITIVE EMOTIONS\n",
      "1 \t SHARING ADVICE\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "23 \t SHARING EXPERIENCES\n",
      "3 \t SHARING OPINIONS AND PREFERENCES\n",
      "2 \t SHARING PERSONAL BACKGROUND\n",
      "1 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "1 \t META DISCUSSION\n",
      "1 \t SHARING FUTURE PLANS\n",
      "\n",
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "25 \t SHARING EXPERIENCES\n",
      "7 \t SHARING OPINIONS AND PREFERENCES\n",
      "4 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "4 \t SHARING PERSONAL BACKGROUND\n",
      "2 \t SHARING NEGATIVE EMOTIONS\n",
      "2 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "1 \t SHARING INFORMATION\n",
      "1 \t SHARING POSITIVE EMOTIONS\n",
      "1 \t SHARING FUTURE PLANS\n",
      "\n",
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "27 \t SHARING EXPERIENCES\n",
      "12 \t SHARING OPINIONS AND PREFERENCES\n",
      "4 \t SHARING FUTURE PLANS\n",
      "1 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "1 \t META DISCUSSION\n",
      "1 \t SHARING PERSONAL BACKGROUND\n",
      "1 \t SHARING ADVICE\n",
      "1 \t SHARING NEGATIVE EMOTIONS\n",
      "1 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "75.0% \t 75 \t SHARING EXPERIENCES\n",
      "22.0% \t 22 \t SHARING OPINIONS AND PREFERENCES\n",
      "7.0% \t 7 \t SHARING PERSONAL BACKGROUND\n",
      "6.0% \t 6 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "6.0% \t 6 \t SHARING FUTURE PLANS\n",
      "3.0% \t 3 \t SHARING NEGATIVE EMOTIONS\n",
      "3.0% \t 3 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "2.0% \t 2 \t NONE\n",
      "2.0% \t 2 \t META DISCUSSION\n",
      "1.0% \t 1 \t SHARING INFORMATION\n",
      "1.0% \t 1 \t SHARING POSITIVE EMOTIONS\n",
      "1.0% \t 1 \t SHARING ADVICE\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "------------------------------------------\n",
      "\n",
      "So if anyone is wondering, I have read all of these comments and they all apply.bloating, nausea, weight/appetite gain (it's been 12 days) extreme rage, breat tenderness and lumps.\n",
      "So i went back again, gave me different meds, which i couldnt take upset stomach along with my regular symptoms then i kept having this pain, and hardness in my lower left abdomen, painful sex, doctor said my cervix and uterus were swollen, cramping, just horrible pain and very annoying.\n",
      "While doing my research I read quite a few reviews about how much it hurt.\n",
      "Before getting this form of birth control, I read tons of reviews.\n",
      "But that was all explained to me before I chose to get it.\n",
      "Also hearing some woman got pregnant while on Nexplanon is scary.\n"
     ]
    }
   ],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'SHARING/DESCRIBING ADDITIONAL RESEARCH':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Backup labeling into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_post_examples = db.get_dataset('discourse-reddit-posts')\n",
    "reddit_comment_examples = db.get_dataset('discourse-reddit-comments')\n",
    "twitter_post_examples = db.get_dataset('discourse-twitter-posts')\n",
    "twitter_replies_examples = db.get_dataset('discourse-twitter-replies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200, 200)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_post_examples), len(reddit_comment_examples), len(twitter_post_examples), len(twitter_replies_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dicts = []\n",
    "for e in reddit_post_examples + reddit_comment_examples + twitter_post_examples + twitter_replies_examples:\n",
    "    for _label in e['accept']:\n",
    "        label_dicts.append({'Source': e['meta']['Source'],\n",
    "                            'ID': e['meta']['ID'],\n",
    "                            'Label': _label,\n",
    "                            'Text': e['text']})\n",
    "    if len(e['accept']) == 0:\n",
    "        label_dicts.append({'Source': e['meta']['Source'],\n",
    "                            'ID': e['meta']['ID'],\n",
    "                            'Label': 'NONE',\n",
    "                            'Text': e['text']})\n",
    "label_df = pd.DataFrame(label_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "narrating personal experiences         275\n",
       "providing information (educational)    125\n",
       "NONE                                   121\n",
       "other discourse                         58\n",
       "negative self-disclosure                44\n",
       "seeking information (educational)       43\n",
       "seeking experiences                     42\n",
       "weighing options                        39\n",
       "providing information (advice)          31\n",
       "providing other experiences             22\n",
       "humor                                   20\n",
       "providing personal experiences          19\n",
       "seeking information (advice)            19\n",
       "politics                                16\n",
       "positive self-disclosure                11\n",
       "providing emotional support              7\n",
       "seeking emotional support                3\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>twitter-replies</td>\n",
       "      <td>408246293442469900</td>\n",
       "      <td>providing information (educational)</td>\n",
       "      <td>IUD removal takes about two seconds &amp;amp; is m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>twitter-replies</td>\n",
       "      <td>332926197128364000</td>\n",
       "      <td>politics</td>\n",
       "      <td>Judge Slams 'Frivolous' Obama Defense Of Birth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>reddit-comments</td>\n",
       "      <td>e2vbh8x</td>\n",
       "      <td>narrating personal experiences</td>\n",
       "      <td>The doctor who removed mine at PP listened int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Source                  ID                                Label  \\\n",
       "677  twitter-replies  408246293442469900  providing information (educational)   \n",
       "877  twitter-replies  332926197128364000                             politics   \n",
       "267  reddit-comments             e2vbh8x       narrating personal experiences   \n",
       "\n",
       "                                                  Text  \n",
       "677  IUD removal takes about two seconds &amp; is m...  \n",
       "877  Judge Slams 'Frivolous' Obama Defense Of Birth...  \n",
       "267  The doctor who removed mine at PP listened int...  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contraceptive pill being available?\n",
      "She only dressed quickly into her underwear and slid the dress over her head.\n",
      "Perhaps he confused them with IUD's?\n",
      "In two months I'll be 18\n",
      "And I probably shouldnt have phrased that the way I did without providing more context.\n",
      "Haha, nothing really.\n",
      "Ughhhh this sucks\n",
      "What's going on?\n",
      "It's always a surprise!\n",
      "Im into distribution, i'm like atlantic.\n"
     ]
    }
   ],
   "source": [
    "for i, r in label_df[label_df['Label'] == 'NONE'].sample(10).iterrows():\n",
    "    print(' '.join(r['Text'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_csv('/Volumes/Passport-1/data/birth-control/labeling/label-sentences/labeled_by_maria.all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try training a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11993"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory_path   = '/Volumes/Passport-1/data/birth-control'\n",
    "test_df = pd.read_csv(data_directory_path + '/labeling/label-sentences/sampled-sentences.test.csv')\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>3859</td>\n",
       "      <td>The only thing that works that late is the cop...</td>\n",
       "      <td>{'ID': 'eyx0ilp', 'Source': 'reddit-comments',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11745</th>\n",
       "      <td>11745</td>\n",
       "      <td>i have been on this for 7 months and i bleed f...</td>\n",
       "      <td>{'ID': 'w11392', 'Source': 'webmd-reviews', 'M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>10011</td>\n",
       "      <td>The entire time was awful.</td>\n",
       "      <td>{'ID': 'w12188', 'Source': 'webmd-reviews', 'M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "3859         3859  The only thing that works that late is the cop...   \n",
       "11745       11745  i have been on this for 7 months and i bleed f...   \n",
       "10011       10011                         The entire time was awful.   \n",
       "\n",
       "                                                    meta  \n",
       "3859   {'ID': 'eyx0ilp', 'Source': 'reddit-comments',...  \n",
       "11745  {'ID': 'w11392', 'Source': 'webmd-reviews', 'M...  \n",
       "10011  {'ID': 'w12188', 'Source': 'webmd-reviews', 'M...  "
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>twitter-posts</td>\n",
       "      <td>300336102865248260</td>\n",
       "      <td>narrating personal experiences</td>\n",
       "      <td>getting the contraceptive implant in possibly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>reddit-posts</td>\n",
       "      <td>gjld30</td>\n",
       "      <td>narrating personal experiences</td>\n",
       "      <td>Although sometimes I feel like I am gonna have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>reddit-posts</td>\n",
       "      <td>c2gb30</td>\n",
       "      <td>seeking information (advice)</td>\n",
       "      <td>Can I take these steri-strips (butterfly stitc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Source                  ID                           Label  \\\n",
       "516  twitter-posts  300336102865248260  narrating personal experiences   \n",
       "96    reddit-posts              gjld30  narrating personal experiences   \n",
       "39    reddit-posts              c2gb30    seeking information (advice)   \n",
       "\n",
       "                                                  Text  \n",
       "516  getting the contraceptive implant in possibly ...  \n",
       "96   Although sometimes I feel like I am gonna have...  \n",
       "39   Can I take these steri-strips (butterfly stitc...  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_label(label, target_label):\n",
    "    if label == target_label:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative self-disclosure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67        17\n",
      "           1       0.59      0.77      0.67        13\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.68      0.68      0.67        30\n",
      "weighted avg       0.69      0.67      0.67        30\n",
      "\n",
      "narrating personal experiences\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        88\n",
      "           1       0.83      0.83      0.83        94\n",
      "\n",
      "    accuracy                           0.82       182\n",
      "   macro avg       0.82      0.82      0.82       182\n",
      "weighted avg       0.82      0.82      0.82       182\n",
      "\n",
      "seeking experiences\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        15\n",
      "           1       0.79      0.85      0.81        13\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.82      0.82      0.82        28\n",
      "weighted avg       0.82      0.82      0.82        28\n",
      "\n",
      "NONE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64        42\n",
      "           1       0.59      0.50      0.54        38\n",
      "\n",
      "    accuracy                           0.60        80\n",
      "   macro avg       0.60      0.60      0.59        80\n",
      "weighted avg       0.60      0.60      0.60        80\n",
      "\n",
      "seeking information (educational)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.53      0.62        15\n",
      "           1       0.61      0.79      0.69        14\n",
      "\n",
      "    accuracy                           0.66        29\n",
      "   macro avg       0.67      0.66      0.65        29\n",
      "weighted avg       0.67      0.66      0.65        29\n",
      "\n",
      "weighing options\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.57      0.64        14\n",
      "           1       0.60      0.75      0.67        12\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.66      0.66      0.65        26\n",
      "weighted avg       0.67      0.65      0.65        26\n",
      "\n",
      "providing information (educational)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.74        41\n",
      "           1       0.73      0.83      0.78        42\n",
      "\n",
      "    accuracy                           0.76        83\n",
      "   macro avg       0.76      0.76      0.76        83\n",
      "weighted avg       0.76      0.76      0.76        83\n",
      "\n",
      "other discourse\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.59      0.63        22\n",
      "           1       0.55      0.65      0.59        17\n",
      "\n",
      "    accuracy                           0.62        39\n",
      "   macro avg       0.62      0.62      0.61        39\n",
      "weighted avg       0.63      0.62      0.62        39\n",
      "\n",
      "providing information (advice)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        12\n",
      "           1       0.69      1.00      0.82         9\n",
      "\n",
      "    accuracy                           0.81        21\n",
      "   macro avg       0.85      0.83      0.81        21\n",
      "weighted avg       0.87      0.81      0.81        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _target_label in label_df['Label'].unique():\n",
    "\n",
    "    _binarized_df = label_df.copy()\n",
    "    _binarized_df['Label'] = label_df['Label'].apply(lambda x: binarize_label(x, _target_label))\n",
    "    _positive_ids = _binarized_df[_binarized_df['Label'] == 1]['ID'].tolist()\n",
    "    _binarized_df = _binarized_df[~((_binarized_df['ID'].isin(_positive_ids)) & (_binarized_df['Label'] == 0))]\n",
    "\n",
    "    _binarized_df = _binarized_df.groupby('Label').sample(n=len(_binarized_df[_binarized_df['Label'] == 1]), random_state=1)\n",
    "\n",
    "    if len(_binarized_df.index) > 50:\n",
    "\n",
    "        _train_df, _test_df = train_test_split(_binarized_df, test_size=0.33, random_state=42)\n",
    "\n",
    "        _train_texts = _train_df['Text']\n",
    "        _train_labels = _train_df['Label']\n",
    "        _test_texts = _test_df['Text']\n",
    "        _test_labels = _test_df['Label']\n",
    "\n",
    "        _vectorizer = TfidfVectorizer()\n",
    "        _X_train = _vectorizer.fit_transform(_train_texts)\n",
    "        _X_test = _vectorizer.transform(_test_texts)\n",
    "\n",
    "        _model = LogisticRegression(C=10).fit(_X_train, _train_labels)\n",
    "        _predictions = _model.predict(_X_test)\n",
    "\n",
    "        print(_target_label)\n",
    "        print(classification_report(_test_labels, _predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16\n",
       "1    16\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_binarized_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[0-9]+', 'NUM', text)\n",
    "    text = re.sub(r'[^\\sA-Za-z0-9À-ÖØ-öø-ÿЀ-ӿ/]', ' \\1 ', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'does this work \\x01 hmmm \\x01 how about this \\x01 \\x01 \\x01'"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = process_string('Does this work? Hmmm,how about this???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "negative self-disclosure\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "the implanon has given me MAD mood swings fml\n",
      "No weight gain either, just got my period a few times/year.\n",
      "So, I started this pill a month and a half and it's been great , I haven't spotted at all or gotten any acne like some have said, but I have been very depressed since starting and it just occurred to me today to look up side effects because I have never felt like this ever\n",
      "A day late isn’t really late.\n",
      "THIS THING!!!good luck and give it a try!~\n",
      "If it gets knocked out it wasnt put in right RT :\n",
      "I had the Implanon and found it sent my sex drive plummeting whilst making me put on weight it was awful\n",
      "Just watched a video of how the nexplanon implant is removed and now I wanna cry😫\n",
      "The chance of an IUD dislodging is actually really low (despite horror stories on reddit).\n",
      "I was looking on getting a implanon but the side effects scare me a bit lol\n",
      "\n",
      "---------------------------------\n",
      "narrating personal experiences\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "well i’ve been like this for sooo many years and it started when i got my nexplanon implant.\n",
      "I start next week\n",
      "i am 25 i have a 4 yearold n do not want anymore children right now i dont like the way hormonal bc makes me feel so i had the paragard put in last week the placement was like a papsmear alittle pressure with a sm pinch took no longer then 5 min...\n",
      "Bad jupiter iud disposition,hermes birkin handbag propaedeutic perish wed which algorithm unto go on unseconde...\n",
      "Taking antibiotics and such.\n",
      "I've been on Aviane for 2 months now.\n",
      "I got my Nexplanon a year ago today I feel blessed\n",
      "I don’t love it so far... hoping it works for me soon!\n",
      "I've been on the implant for a month.\n",
      "Also, it gets worse during my period which is why I had an iud put in despite the pain for 48hrs after insertion.\n",
      "\n",
      "---------------------------------\n",
      "seeking experiences\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "You're doing a lot of research in false places then.\n",
      "Implantation bleeding is a thing that happens for women who experience ovulation spotting.\n",
      "sounds like you!\n",
      "i think she’s saying you probably shouldn’t take an EMERGENCY CONTRACEPTIVE as a regular birth control pill because, as stated before, it can have negative effects on your body no matter who you are.\n",
      "Mayne Pharma (MYX) has entered a long-term supply agreement with Novast Laboratories for 13 U.S. generic oral contraceptive products.\n",
      "She just got a iud placed 😄\n",
      "Skyla IUD expulsion.\n",
      "Extreme menstrual cramps with copper IUD\n",
      "I hope this helps, and if you have anything else you want to know, feel free to ask!\n",
      "Practically cricketing records far fetched: IUD\n",
      "\n",
      "---------------------------------\n",
      "NONE\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "I know this seems like a perfect world scenario, but this does exist where I live!\n",
      "Just so we know what not to recommend, haha.\n",
      "Is there any interaction between these two medications?\n",
      "Don't get this birth control.\n",
      "I'm not pregnant or trying to be tf\n",
      "I need to leave.\n",
      "Being someone who already has an issue with anxiety I'm not sure how much longer i will continue with this pill.\n",
      "Did I tell Y'all I accidentally took a Birth Control pill..?\n",
      "Well good luck with the IUD😭😭😂\n",
      "It'll probably be cheaper.\n",
      "\n",
      "---------------------------------\n",
      "seeking information (educational)\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "I was put on the for acne control.\n",
      "Fifth death associated with controversial Essure birth control implant http://t.co/UFSDRios9T\n",
      "I was in your position.\n",
      "I’ve noticed that my boobs deflated since having the Mirena (to I’m assuming what was my natural size).\n",
      "The fact that it’s normal for women to be in acute pain and abuse OTC pain killers to function because of periods, their endometriosis, or IUD pain is proof we still need feminism\n",
      "They all have said that they have seen these issues with other patients using the Implanon.\n",
      "I often wonder if I would have felt less depressed and anxious as a teen without BC.\n",
      "Sci fiction is now science fact.\n",
      "Open Question: WHEN CAN I FIRST HAVE UNPROTECTED SEX WITH IMPLANON? - http://tinyurl.com/yj2w4ey\n",
      "It is rare yes, but it can happen.\n",
      "\n",
      "---------------------------------\n",
      "weighing options\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "So far only issue ive had are the headaches and minor acne but nothing too severe.\n",
      "Nexplanon baby BABAAY lmao\n",
      "I waited two weeks, dumb i know, but eventually went to see my gyno and was tested for STIs, yeast infection, and BV.\n",
      "Hello everyone, I am going to get an hormonal IUD (Jaydess - UK) inserted in two weeks, so I have been wondering about a few things.\n",
      "I decided I no longer wanted to be on the shot - sick of mood swings, wait gain, and more - after nine years.\n",
      "my disorder is legitimate, so i CAN pull the card.\n",
      "What about an IUD?\n",
      "but it's the same thing as the mirena\n",
      "Weirdly I believe Kyleena has helped reduce my acne\n",
      "Everyone has a different body, but I wish I would've read the reviews before getting this a second time.\n",
      "\n",
      "---------------------------------\n",
      "providing information (educational)\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "Have you tried searching through the subreddit for related discussions?\n",
      "I took a birthday control pill for 10 years with no problems.\n",
      "However in many cases of impending IUD there are established risks of prolonging pregnancy so expedient delivery is\n",
      "so I know it can no longer be adolescent acne).\n",
      "HIV &amp; AIDS Information :: Efavirenz compromises hormonal contraceptive implant http://t.co/bL0SnmjCW2\n",
      "F.D.A. Panel Weighs Complaints on Essure Contraceptive Implant http://t.co/DLR3AmbKSG\n",
      "The only brighside to paraguard is it’s nonhormonal\n",
      "Keep in mind that hormonal emergency contraceptive is not effective for women over 77kg.\n",
      "The good news is these episodes usually resolve within 24 hours regardless.\n",
      "Fifth death associated with controversial Essure birth control implant http://t.co/UFSDRios9T\n",
      "\n",
      "---------------------------------\n",
      "other discourse\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "We're getting closer to the male contraceptive pill say scientists.\n",
      "Birth control pill ftw\n",
      "Chavez, for his many faults, did respect that life begins at conception.\n",
      "It helped me earlier today.\n",
      "US news Study in mice raises hopes for birth control pill for men: CHICAGO (Reuters) - U.S. researchers have stu...\n",
      "Widespread use of the contraceptive pill by women may increase the risk of prostate cancer in men.: submitted by... http://t.co/8fSGTFGP\n",
      "That \"male birth control pill\" needs to be marketed pronto\n",
      "Seconding all of this- excellent feedback!\n",
      "It really hurts and looks awful but once it calms down the bruising will go away and it will be barely noticeable.\n",
      "omg im reading about how it feels to get an IUD inserted and everyone says it's the worst pain ever im SCARED KFKDKD\n",
      "\n",
      "---------------------------------\n",
      "providing information (advice)\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "8 Women Share What It’s Like Switching To An IUD http://t.co/sLCgUeIF1m #tech #wtf #news #gadgets #lol #fun #weird #pics #video\n",
      "Only side effect has been some irregular periods, a little breakthrough bleeding, but totally manageable.\n",
      "Wow so I bought an issue of Vogue and it's actually awful.\n",
      "I was very nervous about going so I'd like to be helpful and answer anyones questions.\n",
      "Headaches, cramps, stomach problems, depression, SEVERE drop in libido(sex makes me want to vomit right now), fatigue, weight gain, everything.\n",
      "It will knock you on your butt!\n",
      "Your emergency fund will just need to get you to a blue state.\n",
      "I can't speak about depo, but like other have said it isn't the best option for long term usage and IUD's aren't that scary!\n",
      "and I did have mood swings sometimes and it didn't kill my libido but don't have sex as much as I used to.\n",
      "Don't get nexplanon ladies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _target_label in label_df['Label'].unique():\n",
    "\n",
    "    _binarized_df = label_df.copy()\n",
    "    _binarized_df['Label'] = label_df['Label'].apply(lambda x: binarize_label(x, _target_label))\n",
    "    _positive_ids = _binarized_df[_binarized_df['Label'] == 1]['ID'].tolist()\n",
    "    _binarized_df = _binarized_df[~((_binarized_df['ID'].isin(_positive_ids)) & (_binarized_df['Label'] == 0))]\n",
    "\n",
    "    _binarized_df = _binarized_df.groupby('Label').sample(n=len(_binarized_df[_binarized_df['Label'] == 1]), random_state=1)\n",
    "\n",
    "    if len(_binarized_df.index) > 50:\n",
    "\n",
    "        _train_texts = _binarized_df['Text']\n",
    "        _train_labels = _binarized_df['Label']\n",
    "\n",
    "        _test_texts = test_df['text']\n",
    "\n",
    "        _train_texts_processed = [process_string(t) for t in _train_texts]\n",
    "        _test_texts_processed  = [process_string(t) for t in _test_texts]\n",
    "\n",
    "        _vectorizer = TfidfVectorizer()\n",
    "        _X_train = _vectorizer.fit_transform(_train_texts_processed)\n",
    "        _X_test = _vectorizer.transform(_test_texts_processed)\n",
    "\n",
    "        _model = LogisticRegression(C=10).fit(_X_train, _train_labels)\n",
    "        _predictions = _model.predict(_X_test)\n",
    "\n",
    "        print('---------------------------------')\n",
    "        print(_target_label)\n",
    "        print('---------------------------------')\n",
    "        print()\n",
    "\n",
    "        _positive_texts = [_text for _prediction, _text in zip(_predictions, _test_texts) if _prediction == 1]\n",
    "        _negative_texts = [_text for _prediction, _text in zip(_predictions, _test_texts) if _prediction == 0]\n",
    "\n",
    "        print('POSITIVE')\n",
    "        for _text in random.sample(_positive_texts, 10):\n",
    "            print(' '.join(_text.split()))\n",
    "        \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6057ff503712b9d8589e95303374a5e0505a3b171f577536b68d8760b171ae5c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('prodigyEnv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

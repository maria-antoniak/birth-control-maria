{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Use \"prodigyEnv\" conda environment for this notebook.\n",
    "\n",
    "To set up Prodigy environment, download the wheel file from the Prodigy email (which you receive after purchasing a license). \n",
    "\n",
    "Then run `pip install ./prodigy*.whl`\n",
    "\n",
    "Instructions: https://prodi.gy/docs/install\n",
    "\n",
    "Database is stored at /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from prodigy.components.db import connect\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_mean(df, by, column, rot=0):\n",
    "    # use dict comprehension to create new dataframe from the iterable groupby object\n",
    "    # each group name becomes a column in the new dataframe\n",
    "    df2 = pd.DataFrame({col:vals[column] for col, vals in df.groupby(by)})\n",
    "    # find and sort the median values in this new dataframe\n",
    "    means = df2.mean().sort_values()\n",
    "    # use the columns in the dataframe, ordered sorted by median value\n",
    "    # return axes so changes can be made outside the function\n",
    "#     return df2[meds.index].boxplot(rot=rot, return_type=\"axes\")\n",
    "    return means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "# Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bc-reddit-posts',\n",
       " 'bc-reddit-comments',\n",
       " 'bc-twitter-posts',\n",
       " 'bc-twitter-replies',\n",
       " 'discourse-webmd-reviews',\n",
       " 'discourse-reddit-posts',\n",
       " 'discourse-reddit-comments',\n",
       " 'discourse-twitter-posts',\n",
       " 'discourse-twitter-replies']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = connect()\n",
    "\n",
    "db.datasets # This will list all of your prodigy databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.drop_dataset('discourse-reddit-comments')  # Only do this if you want to delete all your annotations!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "# Explore REDDIT posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-reddit-posts')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "80 \t SHARING PERSONAL EXPERIENCES\n",
      "31 \t SEEKING INFORMATION\n",
      "27 \t NONE\n",
      "19 \t SHARING OPINIONS AND PREFERENCES\n",
      "16 \t SHARING FUTURE PLANS\n",
      "15 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "13 \t SEEKING EXPERIENCES\n",
      "12 \t SEEKING EMOTIONAL SUPPORT\n",
      "10 \t SHARING PERSONAL BACKGROUND\n",
      "9 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "6 \t SEEKING ADVICE\n",
      "4 \t SEEKING NORMALITY\n",
      "3 \t SHARING INFORMATION\n",
      "2 \t META DISCUSSION\n",
      "2 \t SHARING SECONDHAND EXPERIENCES\n",
      "1 \t SHARING NORMALITY\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "28 \t SHARING PERSONAL EXPERIENCES\n",
      "12 \t SEEKING INFORMATION\n",
      "5 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "5 \t SHARING OPINIONS AND PREFERENCES\n",
      "4 \t SHARING PERSONAL BACKGROUND\n",
      "4 \t SHARING FUTURE PLANS\n",
      "3 \t SEEKING EMOTIONAL SUPPORT\n",
      "2 \t SEEKING EXPERIENCES\n",
      "2 \t SEEKING ADVICE\n",
      "1 \t META DISCUSSION\n",
      "1 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "1 \t SEEKING NORMALITY\n",
      "1 \t SHARING NORMALITY\n",
      "1 \t SHARING INFORMATION\n",
      "\n",
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "26 \t SHARING PERSONAL EXPERIENCES\n",
      "9 \t SEEKING EXPERIENCES\n",
      "9 \t SHARING FUTURE PLANS\n",
      "8 \t SEEKING INFORMATION\n",
      "7 \t SHARING OPINIONS AND PREFERENCES\n",
      "6 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "6 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "5 \t SHARING PERSONAL BACKGROUND\n",
      "4 \t SEEKING EMOTIONAL SUPPORT\n",
      "2 \t SHARING INFORMATION\n",
      "2 \t SEEKING ADVICE\n",
      "1 \t SHARING SECONDHAND EXPERIENCES\n",
      "1 \t META DISCUSSION\n",
      "1 \t SEEKING NORMALITY\n",
      "\n",
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "26 \t SHARING PERSONAL EXPERIENCES\n",
      "11 \t SEEKING INFORMATION\n",
      "7 \t SHARING OPINIONS AND PREFERENCES\n",
      "5 \t SEEKING EMOTIONAL SUPPORT\n",
      "4 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "3 \t SHARING FUTURE PLANS\n",
      "2 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "2 \t SEEKING NORMALITY\n",
      "2 \t SEEKING ADVICE\n",
      "2 \t SEEKING EXPERIENCES\n",
      "1 \t SHARING PERSONAL BACKGROUND\n",
      "1 \t SHARING SECONDHAND EXPERIENCES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "40.0% \t 80 \t SHARING PERSONAL EXPERIENCES\n",
      "15.5% \t 31 \t SEEKING INFORMATION\n",
      "13.5% \t 27 \t NONE\n",
      "9.5% \t 19 \t SHARING OPINIONS AND PREFERENCES\n",
      "8.0% \t 16 \t SHARING FUTURE PLANS\n",
      "7.5% \t 15 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "6.5% \t 13 \t SEEKING EXPERIENCES\n",
      "6.0% \t 12 \t SEEKING EMOTIONAL SUPPORT\n",
      "5.0% \t 10 \t SHARING PERSONAL BACKGROUND\n",
      "4.5% \t 9 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "3.0% \t 6 \t SEEKING ADVICE\n",
      "2.0% \t 4 \t SEEKING NORMALITY\n",
      "1.5% \t 3 \t SHARING INFORMATION\n",
      "1.0% \t 2 \t META DISCUSSION\n",
      "1.0% \t 2 \t SHARING SECONDHAND EXPERIENCES\n",
      "0.5% \t 1 \t SHARING NORMALITY\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "------------------------------------------\n",
      "\n",
      "It lasted for a few weeks but I figured it was because of the change .\n",
      "But I know it will probably take up to 6 months for my body to re-adjust.\n",
      "I thought I would be fine since I was on the depo so long beforehand, and didn't even realize this could possibly be a symptom of the implant.\n",
      "This lasted for MONTHS, so I read somewhere online that vitamin e and zinc help with this, and it did stop the bleeding for a couple weeks, but I just started spotting again today.\n",
      "I'm now doing a 5 month Accutane course as suggested by my dermatologist because I'm still breaking out consistently with large cysts.\n",
      "I am taking the pill continuously to not have a period but this spotting is pretty much a period.\n",
      "Paraguard prolonged period.\n",
      "I'm thinking about counting it as a missed pill and taking another one just to cover all my bases.\n",
      "I know this is normal if you’re off of the pill because your body is getting ready for your period, but I’m wondering what causes this when I’m on the pill?\n",
      "I know the hormones in Mirerna are locally delivered, so theoretically this shouldn't be an issue, but I wanted to know what your experiences are.\n",
      "I think I may have had a cyst rupture, I've had this happened before and it has been that painful.\n",
      "I told her not to but she told me that it will be fine and that it's not strong enough to damage it.\n",
      "I've always been very hesitant with hormonal birth control because it can cause me to be very erratic (which is why I stopped the pill), but weight gain would be even worse.\n",
      "I’m taking bc only for the hope that it makes my period cramps more bearable( not sexually active)- so would it affect anything if I didn’t take it at the same Time?\n",
      "I’m just curious because I feel like all I need is some damn estrogen to stop this bleeding frenzy :(\n"
     ]
    }
   ],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'SHARING CAUSAL REASONING / HYPOTHESIZING':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Explore REDDIT comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-reddit-comments')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "58 \t SHARING PERSONAL EXPERIENCES\n",
      "47 \t SHARING INFORMATION\n",
      "32 \t NONE\n",
      "24 \t SHARING ADVICE\n",
      "16 \t SHARING OPINIONS AND PREFERENCES\n",
      "7 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "7 \t SHARING EMOTIONAL SUPPORT\n",
      "6 \t SHARING FUTURE PLANS\n",
      "6 \t SHARING NORMALITY\n",
      "6 \t SHARING SECONDHAND EXPERIENCES\n",
      "5 \t SEEKING EXPERIENCES\n",
      "5 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "4 \t META DISCUSSION\n",
      "3 \t SHARING PERSONAL BACKGROUND\n",
      "2 \t SEEKING EMOTIONAL SUPPORT\n",
      "1 \t SEEKING INFORMATION\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "18 \t SHARING PERSONAL EXPERIENCES\n",
      "13 \t SHARING INFORMATION\n",
      "9 \t SHARING OPINIONS AND PREFERENCES\n",
      "6 \t SHARING ADVICE\n",
      "3 \t SEEKING EXPERIENCES\n",
      "3 \t SHARING FUTURE PLANS\n",
      "3 \t SHARING NORMALITY\n",
      "3 \t SHARING EMOTIONAL SUPPORT\n",
      "2 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "2 \t META DISCUSSION\n",
      "2 \t SHARING PERSONAL BACKGROUND\n",
      "1 \t SHARING SECONDHAND EXPERIENCES\n",
      "\n",
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "22 \t SHARING PERSONAL EXPERIENCES\n",
      "16 \t SHARING INFORMATION\n",
      "5 \t SHARING ADVICE\n",
      "4 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "4 \t SHARING SECONDHAND EXPERIENCES\n",
      "3 \t SHARING OPINIONS AND PREFERENCES\n",
      "2 \t META DISCUSSION\n",
      "2 \t SHARING EMOTIONAL SUPPORT\n",
      "2 \t SEEKING EMOTIONAL SUPPORT\n",
      "2 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "1 \t SHARING FUTURE PLANS\n",
      "1 \t SEEKING INFORMATION\n",
      "1 \t SHARING NORMALITY\n",
      "1 \t SEEKING EXPERIENCES\n",
      "1 \t SHARING PERSONAL BACKGROUND\n",
      "\n",
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "18 \t SHARING PERSONAL EXPERIENCES\n",
      "18 \t SHARING INFORMATION\n",
      "13 \t SHARING ADVICE\n",
      "4 \t SHARING OPINIONS AND PREFERENCES\n",
      "3 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "2 \t SHARING NORMALITY\n",
      "2 \t SHARING EMOTIONAL SUPPORT\n",
      "2 \t SHARING FUTURE PLANS\n",
      "1 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "1 \t SHARING SECONDHAND EXPERIENCES\n",
      "1 \t SEEKING EXPERIENCES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "29.0% \t 58 \t SHARING PERSONAL EXPERIENCES\n",
      "23.5% \t 47 \t SHARING INFORMATION\n",
      "16.0% \t 32 \t NONE\n",
      "12.0% \t 24 \t SHARING ADVICE\n",
      "8.0% \t 16 \t SHARING OPINIONS AND PREFERENCES\n",
      "3.5% \t 7 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "3.5% \t 7 \t SHARING EMOTIONAL SUPPORT\n",
      "3.0% \t 6 \t SHARING FUTURE PLANS\n",
      "3.0% \t 6 \t SHARING NORMALITY\n",
      "3.0% \t 6 \t SHARING SECONDHAND EXPERIENCES\n",
      "2.5% \t 5 \t SEEKING EXPERIENCES\n",
      "2.5% \t 5 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "2.0% \t 4 \t META DISCUSSION\n",
      "1.5% \t 3 \t SHARING PERSONAL BACKGROUND\n",
      "1.0% \t 2 \t SEEKING EMOTIONAL SUPPORT\n",
      "0.5% \t 1 \t SEEKING INFORMATION\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "------------------------------------------\n",
      "\n",
      "My doctor hasn't been concerned by it.\n",
      "Reading/ watching experience stories has become my nightly routine lol\n",
      "I'm definitely going to ask my doctor about the implant though!\n",
      "I have had a blood clot already and was told not to personally.\n",
      "My gyn knows about my history and didnt advise against it.\n",
      "it even says on the nexplanon site that irregularbleeding is the most common side effect\n",
      "Highly recommend the book Period Repair Manual for tips!!\n"
     ]
    }
   ],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'SHARING/DESCRIBING ADDITIONAL RESEARCH':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Explore TWITTER posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-twitter-posts')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "56 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "46 \t META DISCUSSION\n",
      "34 \t SHARING INFORMATION\n",
      "32 \t NONE\n",
      "31 \t SHARING PERSONAL EXPERIENCES\n",
      "14 \t SHARING OPINIONS AND PREFERENCES\n",
      "13 \t SEEKING INFORMATION\n",
      "12 \t SHARING SECONDHAND EXPERIENCES\n",
      "8 \t SHARING FUTURE PLANS\n",
      "8 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "6 \t SEEKING EMOTIONAL SUPPORT\n",
      "4 \t SEEKING EXPERIENCES\n",
      "3 \t SHARING ADVICE\n",
      "2 \t SHARING PERSONAL BACKGROUND\n",
      "1 \t SEEKING ADVICE\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "18 \t META DISCUSSION\n",
      "12 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "8 \t SHARING PERSONAL EXPERIENCES\n",
      "7 \t SHARING INFORMATION\n",
      "6 \t SEEKING INFORMATION\n",
      "5 \t SHARING OPINIONS AND PREFERENCES\n",
      "5 \t SHARING SECONDHAND EXPERIENCES\n",
      "4 \t SEEKING EMOTIONAL SUPPORT\n",
      "3 \t SHARING FUTURE PLANS\n",
      "2 \t SHARING PERSONAL BACKGROUND\n",
      "2 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "2 \t SEEKING EXPERIENCES\n",
      "1 \t SEEKING ADVICE\n",
      "\n",
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "25 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "21 \t META DISCUSSION\n",
      "17 \t SHARING INFORMATION\n",
      "4 \t SHARING PERSONAL EXPERIENCES\n",
      "3 \t SEEKING INFORMATION\n",
      "1 \t SHARING SECONDHAND EXPERIENCES\n",
      "1 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "1 \t SHARING ADVICE\n",
      "\n",
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "19 \t SHARING PERSONAL EXPERIENCES\n",
      "19 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "10 \t SHARING INFORMATION\n",
      "9 \t SHARING OPINIONS AND PREFERENCES\n",
      "7 \t META DISCUSSION\n",
      "6 \t SHARING SECONDHAND EXPERIENCES\n",
      "5 \t SHARING FUTURE PLANS\n",
      "5 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "4 \t SEEKING INFORMATION\n",
      "2 \t SEEKING EMOTIONAL SUPPORT\n",
      "2 \t SHARING ADVICE\n",
      "2 \t SEEKING EXPERIENCES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "28.0% \t 56 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "23.0% \t 46 \t META DISCUSSION\n",
      "17.0% \t 34 \t SHARING INFORMATION\n",
      "16.0% \t 32 \t NONE\n",
      "15.5% \t 31 \t SHARING PERSONAL EXPERIENCES\n",
      "7.0% \t 14 \t SHARING OPINIONS AND PREFERENCES\n",
      "6.5% \t 13 \t SEEKING INFORMATION\n",
      "6.0% \t 12 \t SHARING SECONDHAND EXPERIENCES\n",
      "4.0% \t 8 \t SHARING FUTURE PLANS\n",
      "4.0% \t 8 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "3.0% \t 6 \t SEEKING EMOTIONAL SUPPORT\n",
      "2.0% \t 4 \t SEEKING EXPERIENCES\n",
      "1.5% \t 3 \t SHARING ADVICE\n",
      "1.0% \t 2 \t SHARING PERSONAL BACKGROUND\n",
      "0.5% \t 1 \t SEEKING ADVICE\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "SHARING INFORMATION\n",
      "------------------------------------------\n",
      "\n",
      "(1960) First contraceptive pill made available for women, who can now make their https://t.co/xdjj2owDmY https://t.co/LfSuOtTsmB\n",
      "It cause a lot of hormonal imbalances.\n",
      "http://t.co/fWeL2X2M IUD Beats Pill at Preventing Pregnancy - WebMD: http://t.co/vpcDmI3X IUD Beats… http://t.co/UvM4gSDM\n",
      "How did she get pregnant &amp; she's on the IUD?\n",
      "RT New Birth Control Pill Beyaz Includes Folic Acid, Columnist Writes http://bit.ly/bFCMNr #contraception #prochoice\n",
      "A male version of the #IUD may finally be on the way!\n",
      "Unlike some other methods, the contraceptive implant is not affected by common antibiotics, diarrhoea or vomiting.\n",
      "https://t.co/pfOHEirbju | Telling the untold - \"Bayer’s Essure Contraceptive Implant, Now With a Warning\" @ https://t.co/7CIckUoKwZ #news\n",
      "Future reproductive lifespan may be lessened in oral contraceptive users: Lower measures of ovarian reserve: http://t.co/QD0Yj8msqB\n",
      "Long-Term Data on Complications Adds to Criticism of Contraceptive Implant Thousands of women who claim they were … http://t.co/wKFFaIn6f1\n",
      "http://t.co/LZybfYES The contraceptive pill could reduce risk of ovarian and uterine cancer in nuns\n",
      "\"Bayer halves the price of its contraceptive implant Jadelle® for women in developing countries\" https://t.co/jyefeOtqtg #pharma #biotech …\n",
      "Yes, that’s been true from the beginning, but shocking to see how long it’s taken to beat back this myth developed to get Vatican support for the pill in 1960s: Contraceptive pill can be taken every day of the month, after scientists dismiss 'Pope rule'' https://t.co/nw67T7io4j\n",
      "1974 — The FDA(US) suspended sale of the Dalkon Shield IUD due to infections and seven documented deaths among users.\n",
      "Health : Contraceptive Pill Nearly Halves Risk of Ovarian Cancer, Research Finds: Women who take the con... http://t.co/6tN8TBU4 #health\n",
      "Where can I get IUD done in London pls #chinonye\n",
      "Women may need to take additional precautions when on the pill and using antibiotics.\n",
      "Birth control pill shrinks part of brain that controls sex drive: research - New York Post https://t.co/oipPYQ9G2x via\n",
      "New Version of Contraceptive Implant Is Easier to Insert: The drugmaker Merck has introduced a new version... http://t.co/LpHqgeKI by\n",
      "Implanon: 98.8% https://t.co/M3HjVKvtlH\n",
      "Bayer’s Essure Contraceptive Implant, Now With a Warning #MedicalDevices #WomenandGirls https://t.co/lnAdFxfSQo\n",
      "Recent study suggests that women taking the contraceptive pill are more likely to be depressed: https://t.co/eImJsR0a3m\n",
      "IUD Proposed to Treat Uterine Cancer http://on.msn.com/cbZyan\n",
      "An emergency contraceptive pill is a tough find in the southern Indian state of Tamil Nadu.\n",
      "6 Things Everywoman Should Know Before Using Oral Contraceptives: Oral contraceptive is the fastest selling me... http://t.co/wdBpIu9lx8\n",
      "\"Women receive a Nexplanon implant in their arm, which provides up to three years of continuous birth control.\"\n",
      "birth control pill comes in easy to take pill form http://t.co/YfyYPt3d7a\n",
      "from #sciencedaily No waiting game: Immediate birth control implant more cost-effective: Women who ... http://t.co/RmkcLDHHWV #pregnancy\n",
      "Prior Oral Contraceptive Use Associated with Better Outcome for Ovarian Cancer Patients https://t.co/LuqR7zMdTx\n",
      "5-day-after Ella contraceptive pill wins FDA approval http://cli.gs/VtNdz\n",
      "Mortality From Ovarian Cancer on Decline in the West Possibly From Birth Control Pill and HRT Use https://t.co/O3vtZsE5XA\n",
      "In news warning over a herbal supplement that can cause failure of the contraceptive pill http://t.co/dBhQh1qDMu #mmia\n",
      "Revised: IUD may increase cancer risk http://t.co/rWiakDzpY4\n",
      "Unisex, hormone-free contraceptive pill on the horizon https://t.co/4ZfigRbsZa\n"
     ]
    }
   ],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'SHARING INFORMATION':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Explore Twitter REPLIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-twitter-replies')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "53 \t SHARING PERSONAL EXPERIENCES\n",
      "43 \t META DISCUSSION\n",
      "38 \t NONE\n",
      "33 \t SHARING INFORMATION\n",
      "19 \t SHARING OPINIONS AND PREFERENCES\n",
      "9 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "8 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "6 \t SHARING PERSONAL BACKGROUND\n",
      "6 \t SHARING SECONDHAND EXPERIENCES\n",
      "5 \t SHARING FUTURE PLANS\n",
      "4 \t SHARING ADVICE\n",
      "3 \t SEEKING EXPERIENCES\n",
      "2 \t SEEKING INFORMATION\n",
      "1 \t SEEKING EMOTIONAL SUPPORT\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "29 \t SHARING PERSONAL EXPERIENCES\n",
      "11 \t SHARING INFORMATION\n",
      "8 \t SHARING OPINIONS AND PREFERENCES\n",
      "5 \t META DISCUSSION\n",
      "4 \t SHARING ADVICE\n",
      "3 \t SHARING PERSONAL BACKGROUND\n",
      "3 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "3 \t SHARING FUTURE PLANS\n",
      "2 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "2 \t SHARING SECONDHAND EXPERIENCES\n",
      "2 \t SEEKING INFORMATION\n",
      "\n",
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "28 \t META DISCUSSION\n",
      "12 \t SHARING PERSONAL EXPERIENCES\n",
      "9 \t SHARING INFORMATION\n",
      "4 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "2 \t SHARING OPINIONS AND PREFERENCES\n",
      "2 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "1 \t SHARING PERSONAL BACKGROUND\n",
      "1 \t SEEKING EXPERIENCES\n",
      "\n",
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "13 \t SHARING INFORMATION\n",
      "12 \t SHARING PERSONAL EXPERIENCES\n",
      "10 \t META DISCUSSION\n",
      "9 \t SHARING OPINIONS AND PREFERENCES\n",
      "4 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "4 \t SHARING SECONDHAND EXPERIENCES\n",
      "2 \t SHARING FUTURE PLANS\n",
      "2 \t SEEKING EXPERIENCES\n",
      "2 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "2 \t SHARING PERSONAL BACKGROUND\n",
      "1 \t SEEKING EMOTIONAL SUPPORT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "26.5% \t 53 \t SHARING PERSONAL EXPERIENCES\n",
      "21.5% \t 43 \t META DISCUSSION\n",
      "19.0% \t 38 \t NONE\n",
      "16.5% \t 33 \t SHARING INFORMATION\n",
      "9.5% \t 19 \t SHARING OPINIONS AND PREFERENCES\n",
      "4.5% \t 9 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "4.0% \t 8 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "3.0% \t 6 \t SHARING PERSONAL BACKGROUND\n",
      "3.0% \t 6 \t SHARING SECONDHAND EXPERIENCES\n",
      "2.5% \t 5 \t SHARING FUTURE PLANS\n",
      "2.0% \t 4 \t SHARING ADVICE\n",
      "1.5% \t 3 \t SEEKING EXPERIENCES\n",
      "1.0% \t 2 \t SEEKING INFORMATION\n",
      "0.5% \t 1 \t SEEKING EMOTIONAL SUPPORT\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "SHARING OPINIONS AND PREFERENCES\n",
      "------------------------------------------\n",
      "\n",
      "oh helll nahhhhhh I had one with hormones and that shit was horrible.\n",
      "im just so reluctant to start meds bc it took so many attempts to get to a contraceptive pill that didnt fuck\n",
      "oh bitch fuck nexplanon.\n",
      "Miruiana sounds too close to the IUD I have\n",
      "on my third mirena iud and can't say enough good things about it although I know my experiences aren't universal, but I haven't had my period in over ten years and I'm so grateful\n",
      "I have the IUD now I’m want something different\n",
      "Now I’m glad I didn’t.\n",
      "yea girl nexplanon for life\n",
      "No babies=happy me\n",
      "I hated the nexplanon!\n",
      "tbh I got nexplanon when I was 26 so I could just avoid that shit altogether\n",
      "i dont think im about that iud life man\n",
      "Best thing i have ever done.\n",
      "Birth control pill ftw\n",
      "I have the paragard because it's hormonal free... girl these hormonal birth controls and I don't mix ...\n",
      "I’m debating on what to do I want to give my body a rest from birth control give myself a couple weeks before going on to something else!\n",
      "Kmsl ion care if they care, but mine can't even touch me after I have mine until my IUD is in\n",
      "Nexplanon &amp; yep.. love it.\n",
      "Bro I am the BFF with the baby and Ian team NEXPLANON\n"
     ]
    }
   ],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'SHARING OPINIONS AND PREFERENCES':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# Explore WebMD reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "examples = db.get_dataset('discourse-webmd-reviews')\n",
    "\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "total number of posts labeled\n",
      "------------------------------------------------------\n",
      "\n",
      "143 \t SHARING PERSONAL EXPERIENCES\n",
      "49 \t SHARING OPINIONS AND PREFERENCES\n",
      "14 \t SHARING PERSONAL BACKGROUND\n",
      "10 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "10 \t SHARING FUTURE PLANS\n",
      "10 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "9 \t NONE\n",
      "6 \t SHARING INFORMATION\n",
      "4 \t META DISCUSSION\n",
      "3 \t SHARING ADVICE\n",
      "2 \t SEEKING EXPERIENCES\n",
      "1 \t SEEKING EMOTIONAL SUPPORT\n",
      "1 \t SHARING SECONDHAND EXPERIENCES\n",
      "1 \t SEEKING NORMALITY\n",
      "1 \t SHARING NORMALITY\n"
     ]
    }
   ],
   "source": [
    "label_count_dict = defaultdict(int)\n",
    "method_label_count_dict = defaultdict(lambda: defaultdict(int))\n",
    "label_texts_dict = defaultdict(list)\n",
    "for e in examples:\n",
    "    for _label in e['accept']:\n",
    "        label_count_dict[_label] += 1\n",
    "        method_label_count_dict[e['meta']['Method']][_label] += 1\n",
    "        label_texts_dict[_label].append(e['text'])\n",
    "    if len(e['accept']) < 1:\n",
    "        label_count_dict['NONE'] += 1\n",
    "        label_texts_dict['NONE'].append(e['text'])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('total number of posts labeled')\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "for _label, _count in sorted(label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "pill\n",
      "--------------------------------\n",
      "40 \t SHARING PERSONAL EXPERIENCES\n",
      "12 \t SHARING OPINIONS AND PREFERENCES\n",
      "7 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "6 \t SHARING FUTURE PLANS\n",
      "4 \t SHARING PERSONAL BACKGROUND\n",
      "3 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "2 \t SHARING INFORMATION\n",
      "2 \t SEEKING EXPERIENCES\n",
      "1 \t META DISCUSSION\n",
      "1 \t SHARING ADVICE\n",
      "\n",
      "--------------------------------\n",
      "iud\n",
      "--------------------------------\n",
      "49 \t SHARING PERSONAL EXPERIENCES\n",
      "13 \t SHARING OPINIONS AND PREFERENCES\n",
      "7 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "6 \t SHARING PERSONAL BACKGROUND\n",
      "3 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "1 \t SHARING INFORMATION\n",
      "1 \t SEEKING EMOTIONAL SUPPORT\n",
      "1 \t SEEKING NORMALITY\n",
      "1 \t META DISCUSSION\n",
      "\n",
      "--------------------------------\n",
      "implant\n",
      "--------------------------------\n",
      "54 \t SHARING PERSONAL EXPERIENCES\n",
      "24 \t SHARING OPINIONS AND PREFERENCES\n",
      "4 \t SHARING FUTURE PLANS\n",
      "4 \t SHARING PERSONAL BACKGROUND\n",
      "3 \t SHARING INFORMATION\n",
      "2 \t META DISCUSSION\n",
      "2 \t SHARING ADVICE\n",
      "1 \t SHARING SECONDHAND EXPERIENCES\n",
      "1 \t SHARING NORMALITY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _method, _label_count_dict in method_label_count_dict.items():\n",
    "    print('--------------------------------')\n",
    "    print(_method)\n",
    "    print('--------------------------------')\n",
    "    for _label, _count in sorted(_label_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(_count, '\\t', _label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "percent of posts with label\n",
      "------------------------------\n",
      "\n",
      "71.5% \t 143 \t SHARING PERSONAL EXPERIENCES\n",
      "24.5% \t 49 \t SHARING OPINIONS AND PREFERENCES\n",
      "7.0% \t 14 \t SHARING PERSONAL BACKGROUND\n",
      "5.0% \t 10 \t SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "5.0% \t 10 \t SHARING FUTURE PLANS\n",
      "5.0% \t 10 \t SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "4.5% \t 9 \t NONE\n",
      "3.0% \t 6 \t SHARING INFORMATION\n",
      "2.0% \t 4 \t META DISCUSSION\n",
      "1.5% \t 3 \t SHARING ADVICE\n",
      "1.0% \t 2 \t SEEKING EXPERIENCES\n",
      "0.5% \t 1 \t SEEKING EMOTIONAL SUPPORT\n",
      "0.5% \t 1 \t SHARING SECONDHAND EXPERIENCES\n",
      "0.5% \t 1 \t SEEKING NORMALITY\n",
      "0.5% \t 1 \t SHARING NORMALITY\n"
     ]
    }
   ],
   "source": [
    "label_percent_dict = {_label: _count/float(len(examples)) for _label, _count in label_count_dict.items()}\n",
    "\n",
    "print('------------------------------')\n",
    "print('percent of posts with label')\n",
    "print('------------------------------')\n",
    "print()\n",
    "for _label, _percent in sorted(label_percent_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(str(round(_percent*100, 1)) + '%', '\\t', label_count_dict[_label], '\\t', _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "------------------------------------------\n",
      "\n",
      "So if anyone is wondering, I have read all of these comments and they all apply.bloating, nausea, weight/appetite gain (it's been 12 days) extreme rage, breat tenderness and lumps.\n",
      "So i went back again, gave me different meds, which i couldnt take upset stomach along with my regular symptoms then i kept having this pain, and hardness in my lower left abdomen, painful sex, doctor said my cervix and uterus were swollen, cramping, just horrible pain and very annoying.\n",
      "I did not research until after placement...\n",
      "While doing my research I read quite a few reviews about how much it hurt.\n",
      "Before getting this form of birth control, I read tons of reviews.\n",
      "But that was all explained to me before I chose to get it.\n",
      "After a couple of excruciating hours trying to decide if it was skylas fault it hurt, I decided to go to the ER.\n",
      "I started taking this pill as \"suppressive\" therapy recommended by my Dr. because of my severe endometriosis.\n",
      "I ran across this thread because I was just curious about my placebo pill \"Kelnor\" I actually take Sprintec.\n",
      "I recently had a chemical pregnancy and suffer constant ovarian cysts so my GP decided to try the final method of birth control the MIRENA.\n"
     ]
    }
   ],
   "source": [
    "for _label, _texts in label_texts_dict.items():\n",
    "    if _label == 'SHARING/DESCRIBING ADDITIONAL RESEARCH':\n",
    "        print('------------------------------------------')\n",
    "        print(_label)\n",
    "        print('------------------------------------------')\n",
    "        print()\n",
    "        for e in _texts:\n",
    "            print(' '.join(e.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "# Backup labeling into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_post_examples = db.get_dataset('discourse-reddit-posts')\n",
    "reddit_comment_examples = db.get_dataset('discourse-reddit-comments')\n",
    "twitter_post_examples = db.get_dataset('discourse-twitter-posts')\n",
    "twitter_replies_examples = db.get_dataset('discourse-twitter-replies')\n",
    "webmd_reviews_examples = db.get_dataset('discourse-webmd-reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200, 200, 200)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_post_examples), len(reddit_comment_examples), len(twitter_post_examples), len(twitter_replies_examples), len(webmd_reviews_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dicts = []\n",
    "for e in reddit_post_examples + reddit_comment_examples + twitter_post_examples + twitter_replies_examples + webmd_reviews_examples:\n",
    "    for _label in e['accept']:\n",
    "        label_dicts.append({'Source': e['meta']['Source'],\n",
    "                            'ID': e['meta']['ID'],\n",
    "                            'Label': _label,\n",
    "                            'Text': e['text']})\n",
    "    if len(e['accept']) == 0:\n",
    "        label_dicts.append({'Source': e['meta']['Source'],\n",
    "                            'ID': e['meta']['ID'],\n",
    "                            'Label': 'NONE',\n",
    "                            'Text': e['text']})\n",
    "label_df = pd.DataFrame(label_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1243"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SHARING PERSONAL EXPERIENCES                365\n",
       "NONE                                        138\n",
       "SHARING INFORMATION                         123\n",
       "SHARING OPINIONS AND PREFERENCES            117\n",
       "META DISCUSSION                              99\n",
       "SHARING/DESCRIBING ADDITIONAL RESEARCH       90\n",
       "SHARING CAUSAL REASONING / HYPOTHESIZING     47\n",
       "SEEKING INFORMATION                          47\n",
       "SHARING FUTURE PLANS                         45\n",
       "SHARING PERSONAL BACKGROUND                  35\n",
       "SHARING ADVICE                               34\n",
       "SHARING SECONDHAND EXPERIENCES               27\n",
       "SEEKING EXPERIENCES                          27\n",
       "SEEKING EMOTIONAL SUPPORT                    22\n",
       "SHARING NORMALITY                             8\n",
       "SEEKING ADVICE                                7\n",
       "SHARING EMOTIONAL SUPPORT                     7\n",
       "SEEKING NORMALITY                             5\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twitter-posts      270\n",
       "webmd-reviews      264\n",
       "reddit-posts       250\n",
       "twitter-replies    230\n",
       "reddit-comments    229\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>reddit-posts</td>\n",
       "      <td>f8a6jp</td>\n",
       "      <td>SHARING FUTURE PLANS</td>\n",
       "      <td>I am getting a copper IUD soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>twitter-posts</td>\n",
       "      <td>230487448063447040</td>\n",
       "      <td>META DISCUSSION</td>\n",
       "      <td>Now I got a baby from a drunk dyslexic”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>twitter-posts</td>\n",
       "      <td>556540323636056060</td>\n",
       "      <td>SHARING/DESCRIBING ADDITIONAL RESEARCH</td>\n",
       "      <td>6 Things Everywoman Should Know Before Using O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Source                  ID  \\\n",
       "106   reddit-posts              f8a6jp   \n",
       "516  twitter-posts  230487448063447040   \n",
       "671  twitter-posts  556540323636056060   \n",
       "\n",
       "                                      Label  \\\n",
       "106                    SHARING FUTURE PLANS   \n",
       "516                         META DISCUSSION   \n",
       "671  SHARING/DESCRIBING ADDITIONAL RESEARCH   \n",
       "\n",
       "                                                  Text  \n",
       "106                    I am getting a copper IUD soon.  \n",
       "516            Now I got a baby from a drunk dyslexic”  \n",
       "671  6 Things Everywoman Should Know Before Using O...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I understand that\n",
      "Bitch i got dick wanna fuck?\n",
      "Vinney said a IUD is a wishbone 😭😭 and these the type niggas BPD hire 🥴\n",
      "Oh you learn something new everyday on this app 😭😭😭😭\n",
      "I guess I’ll have to bear my stupid periods.\n",
      "Crying and hives are included.\n",
      "so I know it’s not him).. and crying about it.\n",
      "I’m so happy to my bih Mother Nature slide down on me this morning.\n",
      "No I totally understand.\n",
      "and she just blew me off im starting to think maybe its from the 5g emf exposure I have all the symptoms\n"
     ]
    }
   ],
   "source": [
    "for i, r in label_df[label_df['Label'] == 'NONE'].sample(10).iterrows():\n",
    "    print(' '.join(r['Text'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_csv('/Users/maria/Documents/data/birth-control/labeling/label-discourse/labeled_by_maria.all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "# Try training a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11993"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory_path   = '/Users/maria/Documents/data/birth-control'\n",
    "test_df = pd.read_csv(data_directory_path + '/labeling/label-discourse/sampled-sentences.test.csv')\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8747</th>\n",
       "      <td>8747</td>\n",
       "      <td>This is the best descriptor for a dear little ...</td>\n",
       "      <td>{'ID': 1211812402435624962, 'Source': 'twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>778</td>\n",
       "      <td>Bcp and nexplanon?</td>\n",
       "      <td>{'ID': '3lzpfj', 'Source': 'reddit-posts', 'Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>7822</td>\n",
       "      <td>ahh, confused as to why a contraceptive implan...</td>\n",
       "      <td>{'ID': 269216691572051968, 'Source': 'twitter-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "8747        8747  This is the best descriptor for a dear little ...   \n",
       "778          778                                 Bcp and nexplanon?   \n",
       "7822        7822  ahh, confused as to why a contraceptive implan...   \n",
       "\n",
       "                                                   meta  \n",
       "8747  {'ID': 1211812402435624962, 'Source': 'twitter...  \n",
       "778   {'ID': '3lzpfj', 'Source': 'reddit-posts', 'Me...  \n",
       "7822  {'ID': 269216691572051968, 'Source': 'twitter-...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1243"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>reddit-posts</td>\n",
       "      <td>y9a6w</td>\n",
       "      <td>SHARING CAUSAL REASONING / HYPOTHESIZING</td>\n",
       "      <td>I know the hormones in Mirerna are locally del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>twitter-posts</td>\n",
       "      <td>1156128897458737200</td>\n",
       "      <td>SEEKING INFORMATION</td>\n",
       "      <td>do u ever lose the weight u gained cause of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>reddit-comments</td>\n",
       "      <td>ch2ap8s</td>\n",
       "      <td>SHARING PERSONAL BACKGROUND</td>\n",
       "      <td>I really, really want them to do that for me i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Source                   ID  \\\n",
       "126     reddit-posts                y9a6w   \n",
       "715    twitter-posts  1156128897458737200   \n",
       "317  reddit-comments              ch2ap8s   \n",
       "\n",
       "                                        Label  \\\n",
       "126  SHARING CAUSAL REASONING / HYPOTHESIZING   \n",
       "715                       SEEKING INFORMATION   \n",
       "317               SHARING PERSONAL BACKGROUND   \n",
       "\n",
       "                                                  Text  \n",
       "126  I know the hormones in Mirerna are locally del...  \n",
       "715  do u ever lose the weight u gained cause of th...  \n",
       "317  I really, really want them to do that for me i...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_label(label, target_label):\n",
    "    if label == target_label:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META DISCUSSION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        34\n",
      "           1       0.70      0.72      0.71        32\n",
      "\n",
      "    accuracy                           0.71        66\n",
      "   macro avg       0.71      0.71      0.71        66\n",
      "weighted avg       0.71      0.71      0.71        66\n",
      "\n",
      "SHARING PERSONAL EXPERIENCES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       130\n",
      "           1       0.79      0.79      0.79       111\n",
      "\n",
      "    accuracy                           0.80       241\n",
      "   macro avg       0.80      0.80      0.80       241\n",
      "weighted avg       0.81      0.80      0.81       241\n",
      "\n",
      "SEEKING EXPERIENCES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67        11\n",
      "           1       0.55      0.86      0.67         7\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.70      0.70      0.67        18\n",
      "weighted avg       0.74      0.67      0.67        18\n",
      "\n",
      "SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77        29\n",
      "           1       0.78      0.81      0.79        31\n",
      "\n",
      "    accuracy                           0.78        60\n",
      "   macro avg       0.78      0.78      0.78        60\n",
      "weighted avg       0.78      0.78      0.78        60\n",
      "\n",
      "SHARING PERSONAL BACKGROUND\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.43      0.52        14\n",
      "           1       0.47      0.70      0.56        10\n",
      "\n",
      "    accuracy                           0.54        24\n",
      "   macro avg       0.57      0.56      0.54        24\n",
      "weighted avg       0.58      0.54      0.54        24\n",
      "\n",
      "SHARING INFORMATION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79        42\n",
      "           1       0.77      0.82      0.80        40\n",
      "\n",
      "    accuracy                           0.79        82\n",
      "   macro avg       0.79      0.79      0.79        82\n",
      "weighted avg       0.79      0.79      0.79        82\n",
      "\n",
      "SHARING SECONDHAND EXPERIENCES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71        11\n",
      "           1       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.79      0.77      0.72        18\n",
      "weighted avg       0.84      0.72      0.72        18\n",
      "\n",
      "NONE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74        48\n",
      "           1       0.72      0.66      0.69        44\n",
      "\n",
      "    accuracy                           0.72        92\n",
      "   macro avg       0.72      0.71      0.72        92\n",
      "weighted avg       0.72      0.72      0.72        92\n",
      "\n",
      "SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75        18\n",
      "           1       0.67      0.86      0.75        14\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.76      0.76      0.75        32\n",
      "weighted avg       0.77      0.75      0.75        32\n",
      "\n",
      "SHARING FUTURE PLANS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        16\n",
      "           1       0.69      0.64      0.67        14\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.70      0.70      0.70        30\n",
      "weighted avg       0.70      0.70      0.70        30\n",
      "\n",
      "SEEKING INFORMATION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.61      0.71        18\n",
      "           1       0.63      0.86      0.73        14\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.74      0.73      0.72        32\n",
      "weighted avg       0.75      0.72      0.72        32\n",
      "\n",
      "SHARING OPINIONS AND PREFERENCES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        36\n",
      "           1       0.69      0.79      0.73        42\n",
      "\n",
      "    accuracy                           0.69        78\n",
      "   macro avg       0.69      0.68      0.68        78\n",
      "weighted avg       0.69      0.69      0.69        78\n",
      "\n",
      "SHARING ADVICE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70        11\n",
      "           1       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.74        23\n",
      "   macro avg       0.75      0.73      0.73        23\n",
      "weighted avg       0.74      0.74      0.74        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _target_label in label_df['Label'].unique():\n",
    "\n",
    "    _binarized_df = label_df.copy()\n",
    "    _binarized_df['Label'] = label_df['Label'].apply(lambda x: binarize_label(x, _target_label))\n",
    "    _positive_ids = _binarized_df[_binarized_df['Label'] == 1]['ID'].tolist()\n",
    "    _binarized_df = _binarized_df[~((_binarized_df['ID'].isin(_positive_ids)) & (_binarized_df['Label'] == 0))]\n",
    "\n",
    "    _binarized_df = _binarized_df.groupby('Label').sample(n=len(_binarized_df[_binarized_df['Label'] == 1]), random_state=1)\n",
    "\n",
    "    if len(_binarized_df.index) > 50:\n",
    "\n",
    "        _train_df, _test_df = train_test_split(_binarized_df, test_size=0.33, random_state=42)\n",
    "\n",
    "        _train_texts = _train_df['Text']\n",
    "        _train_labels = _train_df['Label']\n",
    "        _test_texts = _test_df['Text']\n",
    "        _test_labels = _test_df['Label']\n",
    "\n",
    "        _vectorizer = TfidfVectorizer()\n",
    "        _X_train = _vectorizer.fit_transform(_train_texts)\n",
    "        _X_test = _vectorizer.transform(_test_texts)\n",
    "\n",
    "        _model = LogisticRegression(C=10).fit(_X_train, _train_labels)\n",
    "        _predictions = _model.predict(_X_test)\n",
    "\n",
    "        print(_target_label)\n",
    "        print(classification_report(_test_labels, _predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7\n",
       "1    7\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_binarized_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[0-9]+', 'NUM', text)\n",
    "    text = re.sub(r'[^\\sA-Za-z0-9À-ÖØ-öø-ÿЀ-ӿ/]', ' \\1 ', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = process_string('Does this work? Hmmm,how about this???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "META DISCUSSION\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "why are you tryna keep this baby at all?\n",
      "I have an appointment to get an IUD early next week.\n",
      "How the contraceptive pill changed Britain (BBC): Share With Friends: | | Health - Top Stories News, RSS Feeds... http://t.co/OgsJIjLB\n",
      "Implanon all the way haha\n",
      "Women reassured over safety of Essure birth control implant - http://t.co/xlDdvSGcmb\n",
      "I started birth control pill yesterday hopefully that helps with migraines\n",
      "There are other forms of birth control.\n",
      "Constant mood swings, emotional states, crying at the tiniest things, and everything just seems to be too painful in my head.\n",
      "No thanks, I have an IUD &amp; legal abortion.\n",
      "Take one pill a day in order.\n",
      "\n",
      "---------------------------------\n",
      "SHARING PERSONAL EXPERIENCES\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "I cannot wait to have this gone.\n",
      "they aren't heavier, the cramping isn't any different than without the IUD.\n",
      "Now I'm bleeding off and on.\n",
      "and I gain weight that week.\n",
      "I have been taking this BC for at least 3 years.\n",
      "I only had the implant for a year, and I was starting a bleeding cycle every other week for a full 6-10 days.\n",
      "I’m on camila and it’s not working for me.\n",
      "Speculum in, clean cervix, insert the straw thing to measure my uterus, then IUD, and clip the strings.\n",
      "I don't have a ob-gyn as I got my implant at planned parenthood, so I felt like I had no one to turn to or understand what I was going through.\n",
      "Honestly it's really funny that people don't understand that birth control effects every woman differently so nothing is guarenteed besides pregnancy!\n",
      "\n",
      "---------------------------------\n",
      "SEEKING EXPERIENCES\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "Knowing that you were on the recalled pill may be stressing you out enough to make your period that light.\n",
      "SO ready to get you out of my body!!!!\n",
      "You ladies that don’t get side effects from that implanon bullshit are so lucky.\n",
      "Anyone care to share their experiences using any of these pills?\n",
      "I would still recommend this though because the peace of mind of not getting pregnant.\n",
      "If you're wondering about straight up safety, I believe it one of the most widely used generics?\n",
      "One word, love: Nexplanon.\n",
      "It affected my emotion so severely that I suffered from severe sadness, severe anxiety, severe mood swings and anything else you can imagine that can mess with your overall well being.\n",
      "Anyone else experience this?\n",
      "It’s definitely time for something else but idk what else to get\n",
      "\n",
      "---------------------------------\n",
      "SHARING/DESCRIBING ADDITIONAL RESEARCH\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "Prior Oral Contraceptive Use Associated with Better Outcome for Ovarian Cancer Patients https://t.co/LuqR7zMdTx\n",
      "The birth control pill has always helped my skin, but cur... http://bit.ly/ecnOum\n",
      "everything’s been okay for the most part (haven’t bled yet so that’s great lol)\n",
      "Remote-Controlled Contraceptive Implant\n",
      "“: £30bn bill to purify water system after toxic impact of contraceptive pill http://t.co/VNd8TA9s via ” A big concern\n",
      "Define contraceptive pill?It's the second best thing that a women can keep in her mouth to avoid Pregnancy.\n",
      "I was on the pill before, and while I didn't realize while I was on it, it seemed to be effecting my mood and making me generally unhappy.\n",
      "FDA responds to patient uprising over Bayer's Essure birth control implant http://t.co/NdEKvofTzB\n",
      "For anyones sake that read this, please don't get this!!\n",
      "I have hormonal imbalance, severe cramps and also was looking for a birth control pill.\n",
      "\n",
      "---------------------------------\n",
      "SHARING PERSONAL BACKGROUND\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "I felt like i was going to throw up all day and was full of anxiety.\n",
      "Me: 24, no kids.\n",
      "Dispel cuts in line with high eyesight unite with iud stamps well-dressed upgrow yours collection albums: UIOng\n",
      "Medicaid paid for my IUD completely but offers virtually no mental health coverage in IL, which is hilarious since I'm on disability FOR MI.\n",
      "Just check the strings every once in a while and I am fine.\n",
      "I have gained a kilo or two, but that might be because of other reasons.\n",
      "DOLLARS #OutOfPocket #WtfAmerica Thank you and your sliding scale for saving my health and sanity\n",
      "I have an appointment with my doctor tomorrow to check my thyroid.\n",
      "But my partner wondered if my low sex drive and generally low mood could be caused by the hormones.\n",
      "Got pregnant while actively using Lo Loestrin.\n",
      "\n",
      "---------------------------------\n",
      "SHARING INFORMATION\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "Saxton: IUD position intended &lt; 5 mm from fundus.\n",
      "I do know that it makes a higher risk for them\n",
      "I experienced a little bit of cramping afterwards, but nothing that regular strength Tylenol could not remedy.\n",
      "The Maligned IUD Gets a Second Chance | Magazine http://t.co/hU9NvvD\n",
      "Period does not automatically mean or only mean shedding of the uterine lining.\n",
      "I LOVED IT!\n",
      "Does anyone know if you can skip the white and brown pills on this birth control to avoid a period?\n",
      "Many Women With Essure Birth Control Implant Need Reoperation, Study Finds: New research raises concerns about… http://t.co/05YxnNBfXC\n",
      "Since you are out of it, maybe increasing physical activity?\n",
      "You don't have to remember to take a pill everyday.....and that is AWESOME!!\n",
      "\n",
      "---------------------------------\n",
      "SHARING SECONDHAND EXPERIENCES\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "Ive never had acne before and this did nothing but give me terrible mood swings-- bipolar statusMy motivation in my social life, work life, school life, and work out life has gone from decent to non existent.\n",
      "A gynecologist made a thread on Twitter about how tubal ligation is the only free option available to women.\n",
      "I have horrible bloating and pain on my left side, and I have the weirdest brown colored discharge that makes me have to use panty linters every day.\n",
      "Woman gets pregnant after getting birth control implant http://t.co/IPK8TQJcmd\n",
      "Take painkillers before you go for the IUD insertion and have a hot water bottle/heat pad ready for afterwards.\n",
      "Hard to beat that correction but those IUD’s have caused many an injury as well\n",
      "In the beginning Mirena was awesome.\n",
      "but I have seen a Nexplanon removal and ummmm yeaaah.\n",
      "I've been on the pill for so long it's *almost* routine\n",
      "RT : RT : A birth control pill for men: It makes more sense to pull the bullets ...\n",
      "\n",
      "---------------------------------\n",
      "NONE\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "Nowhere in my message did I mention ‘final say’ though... it literally says ‘a say’ not ‘final say’?\n",
      "Local anesthetic, small cut and quick insertion.\n",
      "I'll probably keep getting them.\n",
      "She said she was having trouble finding it because of my fibrous tissues.\n",
      "Also break through bleeding is pretty common on the low dose pill as well in case that ever happens to you as well :)\n",
      "GOT PREGNANT AFTER BEING ON IT FOR 8 MONTHS\n",
      "Cristal is using an IUD and Blake doesn't know!\n",
      "Insurance would be free or cheaper but she doesn't have insurance cause it's just under her parents and she obviously doesn't want them knowing lol\n",
      "RT : I think they should make a birth control pill for men that converts semen into Kung Fu sound effects.\n",
      "Well I got my arm implant out!\n",
      "\n",
      "---------------------------------\n",
      "SHARING CAUSAL REASONING / HYPOTHESIZING\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "I think I want to worship my IUD right now.\n",
      "The cheap kinds off Amazon are just as effective as the expensive kind from the drugstore.\n",
      "Contraceptive implant + my body's unique ability to bruise like whoa = attractive Christmas wound\n",
      "and I'm shying away from Paragard because of hearing it gives longer heavier periods.\n",
      "That is pretty severe cramps and pain, so yes a doctor visit is definitely in order (and ER, if your doctor can't see you).\n",
      "I had terrible side effects from ortho like moodiness, weight gain, appetite increase.\n",
      "I was previously on Yaz and it was perfect, but because they don't have a generic, and I don't have insurance, I am limited to my chooices.\n",
      "I go online to make a note of when Daylight Savings is for spring/fall, put that as notifications in my device the day before they occur, and a little before I take my pill the day before DST, I set the 24 hour timer (since its unaffected by the time change).\n",
      "I had the nexplanon put in about 3 months ago and so far I am satisfied with it.\n",
      "I am getting mine out and I cannot wait to start feeling normal again.\n",
      "\n",
      "---------------------------------\n",
      "SHARING FUTURE PLANS\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "So.. I am hoping that this will prevent pregnancy.\n",
      "Mirena causes all kinds of side effects, hormonal imbalances, estrogen dominance, silicona and copper toxicity, etc.\n",
      "but you shouldn't be able to get copper toxicity from an IUD untless your body can't process copper hence Wilson's disease\n",
      "I would never do it again.\n",
      "I just had this removed today because my depression is so severe.\n",
      "I'm barely attracted to my partner anymore and it's driving a massive wedge in our relationship, I don't want to cuddle or kiss or be touched.\n",
      "One of my doctors gave me a pill to regulate the bleeding.\n",
      "lmfaooooooo RT : I think my four year old male cousin ate my birth control pill.\n",
      "but I'd do it again and again to guarantee not getting pregnant!\n",
      "nexplanon the thing in my arm\n",
      "\n",
      "---------------------------------\n",
      "SEEKING INFORMATION\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "I’ve had mine a little over a year and have enjoyed it so far!\n",
      "Obviously, I take this medication to prevent pregnancy but the symptoms make you paranoid that you ARE pregnant!\n",
      "Oh damn, so you're probably allergic to IUD's too, huh?\n",
      "This is only recommended for someone who is not having sex, as if you were having sex this month, this could lead to an unwanted pregnancy, but as you wont be having sex in the next 14 days, this is something you could try.\n",
      "I must say, the 2nd time around is alot more painful than the first.\n",
      "Do you mean combination pill?\n",
      "Glad to hear the removal went well.\n",
      "How much is an IUD? 1500.\n",
      "So, the implant is typically inserted right around the ulnar nerve, which travels from your neck all the way down to your hand.\n",
      "If it was meant to be taken out as easily as a tampon, it would be possible.\n",
      "\n",
      "---------------------------------\n",
      "SHARING OPINIONS AND PREFERENCES\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "I Armored up with Nexplanon.\n",
      "One of the things that hormonal IUDs do is thin the lining of the uterine wall to prevent a fertilized egg from attaching, and depending on the *strength* of hormones in the IUD, it does that more or less.\n",
      "A gynecologist made a thread on Twitter about how tubal ligation is the only free option available to women.\n",
      "Or different medications that interfere with the efficacy of the birth control pill.\n",
      "I started the first year with no period whatsoever and slowly moved to having a very very light period which lasts a week every five or six weeks.\n",
      "I am very happy with this method.\n",
      "Getting real tiresome\n",
      "It's such a relief, but it was worth it to push through the shitty parts of it.\n",
      "but I never had cramps naturally.\n",
      "My acne cleared up and my periods stopped completely.\n",
      "\n",
      "---------------------------------\n",
      "SHARING ADVICE\n",
      "---------------------------------\n",
      "\n",
      "POSITIVE\n",
      "The abortion argument will be nullified.\n",
      "Sorry but if I’m a girl there is no FUCKING way I’m trusting Nexplanon\n",
      "What side effects can I expect with the implant removal?\n",
      "I use nexplanon (the arm implant) and I love it!\n",
      "I'm just a writer.\n",
      "Questions about implanon removal?\n",
      "Getting your nexplanon taken out isn’t as bad as the videos you watched.\n",
      "but i didnt know if it actually works, i might try to get my hands on some.\n",
      "if you've ever had the rod / contraceptive implant did you gain weight?\n",
      "The Copper IUD (Paragard) is the most effective form of emergency contraception.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _target_label in label_df['Label'].unique():\n",
    "\n",
    "    _binarized_df = label_df.copy()\n",
    "    _binarized_df['Label'] = label_df['Label'].apply(lambda x: binarize_label(x, _target_label))\n",
    "    _positive_ids = _binarized_df[_binarized_df['Label'] == 1]['ID'].tolist()\n",
    "    _binarized_df = _binarized_df[~((_binarized_df['ID'].isin(_positive_ids)) & (_binarized_df['Label'] == 0))]\n",
    "\n",
    "    _binarized_df = _binarized_df.groupby('Label').sample(n=len(_binarized_df[_binarized_df['Label'] == 1]), random_state=1)\n",
    "\n",
    "    if len(_binarized_df.index) > 50:\n",
    "\n",
    "        _train_texts = _binarized_df['Text']\n",
    "        _train_labels = _binarized_df['Label']\n",
    "\n",
    "        _test_texts = test_df['text']\n",
    "\n",
    "        _train_texts_processed = [process_string(t) for t in _train_texts]\n",
    "        _test_texts_processed  = [process_string(t) for t in _test_texts]\n",
    "\n",
    "        _vectorizer = TfidfVectorizer()\n",
    "        _X_train = _vectorizer.fit_transform(_train_texts_processed)\n",
    "        _X_test = _vectorizer.transform(_test_texts_processed)\n",
    "\n",
    "        _model = LogisticRegression(C=10).fit(_X_train, _train_labels)\n",
    "        _predictions = _model.predict(_X_test)\n",
    "\n",
    "        print('---------------------------------')\n",
    "        print(_target_label)\n",
    "        print('---------------------------------')\n",
    "        print()\n",
    "\n",
    "        _positive_texts = [_text for _prediction, _text in zip(_predictions, _test_texts) if _prediction == 1]\n",
    "        _negative_texts = [_text for _prediction, _text in zip(_predictions, _test_texts) if _prediction == 0]\n",
    "\n",
    "        print('POSITIVE')\n",
    "        for _text in random.sample(_positive_texts, 10):\n",
    "            print(' '.join(_text.split()))\n",
    "        \n",
    "        print()\n",
    "\n",
    "        print(classification_report(_test_labels, _predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6057ff503712b9d8589e95303374a5e0505a3b171f577536b68d8760b171ae5c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('prodigyEnv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

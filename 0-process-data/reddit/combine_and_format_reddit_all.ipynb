{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import dill\n",
    "from itertools import permutations, combinations\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "sns.set(style='ticks', font_scale=1.2)\n",
    "\n",
    "import little_mallet_wrapper as lmw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_directory_path = '/Volumes/Passport-1/data/birth-control/reddit/scraped'\n",
    "data_directory_path   = '/Volumes/Passport-1/data/birth-control'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# Extract pill keywords from WebMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'sprintec', 'yaz', 'tri-sprintec', 'loestrin', 'lo-loestrin-fe', 'trinessa', 'junel-fe', 'generess-fe', 'mononessa', 'seasonique', 'azurette', 'minastrin', 'beyaz', 'ocella', 'lutera', 'ortho-tri-cyclen-lo', 'microgestin-fe', 'loryna', 'errin', 'gildess-fe', 'sronyx', 'necon', 'tri-previfem', 'cryselle', 'yasmin', 'viorele', 'jolivette', 'aviane', 'natazia', 'reclipsen', 'apri', 'ortho-tri-cyclen', 'femcon-fe-tablet-chewable', 'camila', 'jolessa', 'amethia', 'kariva', 'nora-be', 'quasense', 'ortho-cyclen', 'junel-fe', 'gianvi', 'low-ogestrel', 'microgestin-fe', 'lybrel', 'enpresse', 'ortho-micronor', 'tri-estarylla', 'loseasonique', 'trivora', 'balziva', 'alesse', 'aubra', 'vestura', 'lo-ovral', 'nortrel', 'camrese', 'levora', 'portia', 'chateal', 'zovia', 'orsythia', 'tri-lo-sprintec', 'nortrel', 'levora', 'mono-linyah', 'microgestin', 'junel', 'norethindrone', 'previfem', 'nikki', 'syeda', 'lessina', 'zenchent', 'tarina-fe', 'loestrin-fe', 'falmina', 'tri-linyah', 'tilia-fe', 'vienva', 'introvale', 'lomedia', 'desogen-tablet', 'norgestimate-ethinyl-estradiol', 'emoquette', 'alyacen', 'quartette', 'altavera', 'daysee', 'kelnor', 'necon-triphasic', 'amethyst', 'nor-q-d-tablet', 'junel', 'mircette', 'safyral', 'caziant', 'micronor', 'enskyce', 'estarylla', 'heather', 'tri-legest-fe', 'zarah', 'nortrel-triphasic', 'levlen', 'amethia-lo', 'ashlyna', 'ortho-tri-cyclen', 'blisovi-fe', 'microgestin', 'lyza', 'camrese-lo', 'loestrin', 'solia-tablet', 'kurvelo', 'levonorgestrel-ec', 'ortho-novum', 'ortho-novum-triphasic', 'cyclafem', 'myzilra', 'necon', 'norinyl', 'estrostep-fe', 'velivet', 'ovcon', 'cyclessa', 'ovcon', 'marlissa', 'sharobel', 'ortho-cept', 'ortho-cyclen', 'loestrin-fe', 'zeosa-tablet-chewable', 'pimtrea', 'gildess', 'dasetta', 'necon', 'norgestrel-ethiny-estra', 'leena', 'larin-fe', 'triphasil', 'levora', 'larissia', 'loestrin', 'nordette', 'desogestrel-ethinyl-estradiol', 'vyfemla', 'zenchent-fe', 'ogestrel', 'low-ogestrel', 'necon', 'norethindron-ethinyl-estradiol-tablet-contraceptives', 'nortrel', 'demulen', 'dasetta-triphasic', 'tri-norinyl', 'tri-levlen', 'blisovi', 'zovia', 'isibloom', 'alesse', 'tri sprintec', 'lo loestrin fe', 'junel fe', 'generess fe', 'ortho tri cyclen lo', 'microgestin fe', 'gildess fe', 'tri previfem', 'ortho tri cyclen', 'femcon fe tablet chewable', 'nora be', 'ortho cyclen', 'junel fe', 'low ogestrel', 'microgestin fe', 'ortho micronor', 'tri estarylla', 'lo ovral', 'tri lo sprintec', 'mono linyah', 'tarina fe', 'loestrin fe', 'tri linyah', 'tilia fe', 'desogen tablet', 'norgestimate ethinyl estradiol', 'necon triphasic', 'nor q d tablet', 'tri legest fe', 'nortrel triphasic', 'amethia lo', 'ortho tri cyclen', 'blisovi fe', 'camrese lo', 'solia tablet', 'levonorgestrel ec', 'ortho novum', 'ortho novum triphasic', 'estrostep fe', 'ortho cept', 'ortho cyclen', 'loestrin fe', 'zeosa tablet chewable', 'norgestrel ethiny estra', 'larin fe', 'desogestrel ethinyl estradiol', 'zenchent fe', 'low ogestrel', 'norethindron ethinyl estradiol tablet contraceptives', 'dasetta triphasic', 'tri norinyl', 'tri levlen'\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webmd_pill_keywords = ['sprintec', 'yaz', 'tri-sprintec', 'loestrin', 'lo-loestrin-fe', 'trinessa', 'junel-fe', 'generess-fe', 'mononessa', 'seasonique', 'azurette', \n",
    "                       'minastrin', 'beyaz', 'ocella', 'lutera', 'ortho-tri-cyclen-lo', 'microgestin-fe', 'loryna', 'errin', 'gildess-fe', 'sronyx', 'necon', \n",
    "                       'tri-previfem', 'cryselle', 'yasmin', 'viorele', 'jolivette', 'aviane', 'natazia', 'reclipsen', 'apri', 'ortho-tri-cyclen', \n",
    "                       'femcon-fe-tablet-chewable', 'camila', 'jolessa', 'amethia', 'kariva', 'nora-be', 'quasense', 'ortho-cyclen', 'junel-fe', 'gianvi', 'low-ogestrel', \n",
    "                       'microgestin-fe', 'lybrel', 'enpresse', 'ortho-micronor', 'tri-estarylla', 'loseasonique', 'trivora', 'balziva', 'alesse', 'aubra', 'vestura', \n",
    "                       'lo-ovral', 'nortrel', 'camrese', 'levora', 'portia', 'chateal', 'zovia', 'orsythia', 'tri-lo-sprintec', 'nortrel', 'levora', 'mono-linyah', \n",
    "                       'microgestin', 'junel', 'norethindrone', 'previfem', 'nikki', 'syeda', 'lessina', 'zenchent', 'tarina-fe', 'loestrin-fe', 'falmina', 'tri-linyah', \n",
    "                       'tilia-fe', 'vienva', 'introvale', 'lomedia', 'desogen-tablet', 'norgestimate-ethinyl-estradiol', 'emoquette', 'alyacen', 'quartette', 'altavera', \n",
    "                       'daysee', 'kelnor', 'necon-triphasic', 'amethyst', 'nor-q-d-tablet', 'junel', 'mircette', 'safyral', 'caziant', 'micronor', 'enskyce', 'estarylla', \n",
    "                       'heather', 'tri-legest-fe', 'zarah', 'nortrel-triphasic', 'levlen', 'amethia-lo', 'ashlyna', 'ortho-tri-cyclen', 'blisovi-fe', 'microgestin', 'lyza', \n",
    "                       'camrese-lo', 'loestrin', 'solia-tablet', 'kurvelo', 'levonorgestrel-ec', 'ortho-novum', 'ortho-novum-triphasic', 'cyclafem', 'myzilra', 'necon', \n",
    "                       'norinyl', 'estrostep-fe', 'velivet', 'ovcon', 'cyclessa', 'ovcon', 'marlissa', 'sharobel', 'ortho-cept', 'ortho-cyclen', 'loestrin-fe', \n",
    "                       'zeosa-tablet-chewable', 'pimtrea', 'gildess', 'dasetta', 'necon', 'norgestrel-ethiny-estra', 'leena', 'larin-fe', 'triphasil', 'levora', 'larissia', \n",
    "                       'loestrin', 'nordette', 'desogestrel-ethinyl-estradiol', 'vyfemla', 'zenchent-fe', 'ogestrel', 'low-ogestrel', 'necon', 'norethindron-ethinyl-estradiol-tablet-contraceptives', \n",
    "                       'nortrel', 'demulen', 'dasetta-triphasic', 'tri-norinyl', 'tri-levlen', 'blisovi', 'zovia', 'isibloom', 'alesse']\n",
    "webmd_pill_keywords += [n.replace('-', ' ') for n in webmd_pill_keywords if '-' in n]\n",
    "\n",
    "', '.join([\"'\" + n + \"'\" for n in webmd_pill_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'oral contracept', 'oral birth control', 'pill', 'pills', 'minipill', 'levonorgestrel', 'femcon', 'desogestrel', 'larin', 'norgestimate', 'zeosa', 'tilia', 'desogen', 'nor', 'generess', 'norgestrel', 'estrostep', 'tarina', 'solia', 'loestren', 'loloestrin', 'gedarel', 'pack', 'placebo', 'tri cyclen', 'tricyclen', 'linessa', 'taytulla', 'lolo', 'tri jordyna', 'trijordyna'\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_reddit_pill_keywords = []\n",
    "for _keyword in type_keywords_dict['pill']:\n",
    "    if _keyword not in webmd_pill_keywords:\n",
    "        remaining_reddit_pill_keywords.append(_keyword)\n",
    "', '.join([\"'\" + n + \"'\" for n in remaining_reddit_pill_keywords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# Final keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_keywords_dict = {'iud': ['iud', 'mirena', 'skyla', 'liletta', 'paragard', 'paraguard', 'kyleena', 'copper', 'coil'], \n",
    "                      'implant': ['implanon', 'nexplanon', 'implant', 'norplant'],\n",
    "                      'ring': ['nuvaring', 'etonogestrel', 'ring', 'nuva ring'], \n",
    "                      'shot': ['shot',  'inject', 'injection', 'depo', 'provera', 'depoprovera'], \n",
    "                      'patch': ['ortho evra', 'xulane', 'patch'],\n",
    "                      'pill': ['oral contracept', 'oral birth control', 'pill', 'pills', 'minipill', 'levonorgestrel', 'femcon', 'desogestrel', 'larin', 'norgestimate', \n",
    "                               'zeosa', 'tilia', 'desogen', 'nor', 'generess', 'norgestrel', 'estrostep', 'tarina', 'solia', 'loestren', 'loloestrin', 'gedarel', 'pack', \n",
    "                               'placebo', 'tri cyclen', 'tricyclen', 'linessa', 'taytulla', 'lolo', 'tri jordyna', 'trijordyna',\n",
    "                               'sprintec', 'yaz', 'tri-sprintec', 'loestrin', 'lo-loestrin-fe', 'trinessa', 'junel-fe', 'generess-fe', 'mononessa', 'seasonique', 'azurette', \n",
    "                               'minastrin', 'beyaz', 'ocella', 'lutera', 'ortho-tri-cyclen-lo', 'microgestin-fe', 'loryna', 'errin', 'gildess-fe', 'sronyx', 'necon', \n",
    "                               'tri-previfem', 'cryselle', 'yasmin', 'viorele', 'jolivette', 'aviane', 'natazia', 'reclipsen', 'apri', 'ortho-tri-cyclen', 'femcon-fe-tablet-chewable', \n",
    "                               'camila', 'jolessa', 'amethia', 'kariva', 'nora-be', 'quasense', 'ortho-cyclen', 'junel-fe', 'gianvi', 'low-ogestrel', 'microgestin-fe', \n",
    "                               'lybrel', 'enpresse', 'ortho-micronor', 'tri-estarylla', 'loseasonique', 'trivora', 'balziva', 'alesse', 'aubra', 'vestura', 'lo-ovral', 'nortrel', \n",
    "                               'camrese', 'levora', 'portia', 'chateal', 'zovia', 'orsythia', 'tri-lo-sprintec', 'nortrel', 'levora', 'mono-linyah', 'microgestin', 'junel', \n",
    "                               'norethindrone', 'previfem', 'nikki', 'syeda', 'lessina', 'zenchent', 'tarina-fe', 'loestrin-fe', 'falmina', 'tri-linyah', 'tilia-fe', 'vienva', \n",
    "                               'introvale', 'lomedia', 'desogen-tablet', 'norgestimate-ethinyl-estradiol', 'emoquette', 'alyacen', 'quartette', 'altavera', 'daysee', 'kelnor', \n",
    "                               'necon-triphasic', 'amethyst', 'nor-q-d-tablet', 'junel', 'mircette', 'safyral', 'caziant', 'micronor', 'enskyce', 'estarylla', 'heather', \n",
    "                               'tri-legest-fe', 'zarah', 'nortrel-triphasic', 'levlen', 'amethia-lo', 'ashlyna', 'ortho-tri-cyclen', 'blisovi-fe', 'microgestin', 'lyza', 'camrese-lo', \n",
    "                               'loestrin', 'solia-tablet', 'kurvelo', 'levonorgestrel-ec', 'ortho-novum', 'ortho-novum-triphasic', 'cyclafem', 'myzilra', 'necon', 'norinyl', \n",
    "                               'estrostep-fe', 'velivet', 'ovcon', 'cyclessa', 'ovcon', 'marlissa', 'sharobel', 'ortho-cept', 'ortho-cyclen', 'loestrin-fe', 'zeosa-tablet-chewable', \n",
    "                               'pimtrea', 'gildess', 'dasetta', 'necon', 'norgestrel-ethiny-estra', 'leena', 'larin-fe', 'triphasil', 'levora', 'larissia', 'loestrin', 'nordette', \n",
    "                               'desogestrel-ethinyl-estradiol', 'vyfemla', 'zenchent-fe', 'ogestrel', 'low-ogestrel', 'necon', 'norethindron-ethinyl-estradiol-tablet-contraceptives', \n",
    "                               'nortrel', 'demulen', 'dasetta-triphasic', 'tri-norinyl', 'tri-levlen', 'blisovi', 'zovia', 'isibloom', 'alesse', 'tri sprintec', 'lo loestrin fe', \n",
    "                               'junel fe', 'generess fe', 'ortho tri cyclen lo', 'microgestin fe', 'gildess fe', 'tri previfem', 'ortho tri cyclen', 'femcon fe tablet chewable', \n",
    "                               'nora be', 'ortho cyclen', 'junel fe', 'low ogestrel', 'microgestin fe', 'ortho micronor', 'tri estarylla', 'lo ovral', 'tri lo sprintec', 'mono linyah', \n",
    "                               'tarina fe', 'loestrin fe', 'tri linyah', 'tilia fe', 'desogen tablet', 'norgestimate ethinyl estradiol', 'necon triphasic', 'nor q d tablet', \n",
    "                               'tri legest fe', 'nortrel triphasic', 'amethia lo', 'ortho tri cyclen', 'blisovi fe', 'camrese lo', 'solia tablet', 'levonorgestrel ec', 'ortho novum', \n",
    "                               'ortho novum triphasic', 'estrostep fe', 'ortho cept', 'ortho cyclen', 'loestrin fe', 'zeosa tablet chewable', 'norgestrel ethiny estra', 'larin fe', \n",
    "                               'desogestrel ethinyl estradiol', 'zenchent fe', 'low ogestrel', 'norethindron ethinyl estradiol tablet contraceptives', 'dasetta triphasic', 'tri norinyl', 'tri levlen'],\n",
    "                     'emergency': ['plan b', 'emergency contraception', 'morning after', 'morningafter', 'norlevo'],\n",
    "                     'barrier': ['condom', 'condoms', 'diaphragm', 'diaphram', 'barrier', 'spermicide', 'cap', 'sponge', 'vcf', 'encare', 'conceptrol', 'foam', 'film'],\n",
    "                     'sterilization': ['sterilize', 'sterilization', 'sterilise', 'sterilisation', 'tubes tied', 'tie my tubes', 'vasectomy'],\n",
    "                     'withdrawal': ['withdrawal', 'withdraw', 'pull out'],\n",
    "                     'ring': ['ring', 'nuvaring'],\n",
    "                     'periodic abstinence': ['rhythm method', 'natural family planning', 'nfp', 'fam', 'fertility awareness', \n",
    "                                             'symptothermal', 'sympto-thermal', 'sympto thermal', 'basal body', 'natural cycles',\n",
    "                                             'calendar method', 'bbt', 'cervical mucus method', 'kindara', 'fertility tracking']}\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _type in type_keywords_dict.keys():\n",
    "    type_keywords_dict[_type] = list(set(type_keywords_dict[_type]))\n",
    "\n",
    "for _type, _words in type_keywords_dict.items():\n",
    "    assert len(_words) == len(list(set(_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iud\n",
      "coil, copper, iud, kyleena, liletta, mirena, paragard, paraguard, skyla\n",
      "\n",
      "implant\n",
      "implanon, implant, nexplanon, norplant\n",
      "\n",
      "ring\n",
      "nuvaring, ring\n",
      "\n",
      "shot\n",
      "depo, depoprovera, inject, injection, provera, shot\n",
      "\n",
      "patch\n",
      "ortho evra, patch, xulane\n",
      "\n",
      "pill\n",
      "alesse, altavera, alyacen, amethia, amethia lo, amethia-lo, amethyst, apri, ashlyna, aubra, aviane, azurette, balziva, beyaz, blisovi, blisovi fe, blisovi-fe, camila, camrese, camrese lo, camrese-lo, caziant, chateal, cryselle, cyclafem, cyclessa, dasetta, dasetta triphasic, dasetta-triphasic, daysee, demulen, desogen, desogen tablet, desogen-tablet, desogestrel, desogestrel ethinyl estradiol, desogestrel-ethinyl-estradiol, emoquette, enpresse, enskyce, errin, estarylla, estrostep, estrostep fe, estrostep-fe, falmina, femcon, femcon fe tablet chewable, femcon-fe-tablet-chewable, gedarel, generess, generess fe, generess-fe, gianvi, gildess, gildess fe, gildess-fe, heather, introvale, isibloom, jolessa, jolivette, junel, junel fe, junel-fe, kariva, kelnor, kurvelo, larin, larin fe, larin-fe, larissia, leena, lessina, levlen, levonorgestrel, levonorgestrel ec, levonorgestrel-ec, levora, linessa, lo loestrin fe, lo ovral, lo-loestrin-fe, lo-ovral, loestren, loestrin, loestrin fe, loestrin-fe, lolo, loloestrin, lomedia, loryna, loseasonique, low ogestrel, low-ogestrel, lutera, lybrel, lyza, marlissa, microgestin, microgestin fe, microgestin-fe, micronor, minastrin, minipill, mircette, mono linyah, mono-linyah, mononessa, myzilra, natazia, necon, necon triphasic, necon-triphasic, nikki, nor, nor q d tablet, nor-q-d-tablet, nora be, nora-be, nordette, norethindron ethinyl estradiol tablet contraceptives, norethindron-ethinyl-estradiol-tablet-contraceptives, norethindrone, norgestimate, norgestimate ethinyl estradiol, norgestimate-ethinyl-estradiol, norgestrel, norgestrel ethiny estra, norgestrel-ethiny-estra, norinyl, nortrel, nortrel triphasic, nortrel-triphasic, ocella, ogestrel, oral birth control, oral contracept, orsythia, ortho cept, ortho cyclen, ortho micronor, ortho novum, ortho novum triphasic, ortho tri cyclen, ortho tri cyclen lo, ortho-cept, ortho-cyclen, ortho-micronor, ortho-novum, ortho-novum-triphasic, ortho-tri-cyclen, ortho-tri-cyclen-lo, ovcon, pack, pill, pills, pimtrea, placebo, portia, previfem, quartette, quasense, reclipsen, safyral, seasonique, sharobel, solia, solia tablet, solia-tablet, sprintec, sronyx, syeda, tarina, tarina fe, tarina-fe, taytulla, tilia, tilia fe, tilia-fe, tri cyclen, tri estarylla, tri jordyna, tri legest fe, tri levlen, tri linyah, tri lo sprintec, tri norinyl, tri previfem, tri sprintec, tri-estarylla, tri-legest-fe, tri-levlen, tri-linyah, tri-lo-sprintec, tri-norinyl, tri-previfem, tri-sprintec, tricyclen, trijordyna, trinessa, triphasil, trivora, velivet, vestura, vienva, viorele, vyfemla, yasmin, yaz, zarah, zenchent, zenchent fe, zenchent-fe, zeosa, zeosa tablet chewable, zeosa-tablet-chewable, zovia\n",
      "\n",
      "emergency\n",
      "emergency contraception, morning after, morningafter, norlevo, plan b\n",
      "\n",
      "barrier\n",
      "barrier, cap, conceptrol, condom, condoms, diaphragm, diaphram, encare, film, foam, spermicide, sponge, vcf\n",
      "\n",
      "sterilization\n",
      "sterilisation, sterilise, sterilization, sterilize, tie my tubes, tubes tied, vasectomy\n",
      "\n",
      "withdrawal\n",
      "pull out, withdraw, withdrawal\n",
      "\n",
      "periodic abstinence\n",
      "basal body, bbt, calendar method, cervical mucus method, fam, fertility awareness, fertility tracking, kindara, natural cycles, natural family planning, nfp, rhythm method, sympto thermal, sympto-thermal, symptothermal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _type, _keywords in type_keywords_dict.items():\n",
    "    print(_type)\n",
    "    print(', '.join(sorted(_keywords)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_types_from_post(r):\n",
    "    \n",
    "    test_tokens = r['tokens_text'].split()\n",
    "\n",
    "    # Count how many times each type appears in the text\n",
    "    type_count_dict = defaultdict(int)\n",
    "    for _type, _keywords in type_keywords_dict.items():\n",
    "        for _word in _keywords:\n",
    "            if len(_word.split()) == 1:\n",
    "                type_count_dict[_type] += len([t for t in test_tokens if t == _word])\n",
    "            elif len(_word.split()) > 1:\n",
    "                type_count_dict[_type] += len(re.findall(_word, ' '.join(test_tokens)))\n",
    "\n",
    "    if len(type_count_dict) > 0:\n",
    "        return list(set([_type for _type, _count in type_count_dict.items() if _count > 0]))\n",
    "\n",
    "    # If there were no type mentions at all, return this\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_type(r):\n",
    "\n",
    "    if str(r['id']) in comment_parent_dict and comment_parent_dict[str(r['id'])] in post_type_dict:\n",
    "        return post_type_dict[comment_parent_dict[str(r['id'])]]\n",
    "\n",
    "    return 'unknown'\n",
    "\n",
    "\n",
    "def get_all_types_from_comment(r):\n",
    "\n",
    "    test_tokens = str(r['tokens_text']).split()\n",
    "\n",
    "    # Count how many times each type appears in the text\n",
    "    type_count_dict = defaultdict(int)\n",
    "    for _type, _keywords in type_keywords_dict.items():\n",
    "        for _word in _keywords:\n",
    "            if len(_word.split()) == 1:\n",
    "                type_count_dict[_type] += len([t for t in test_tokens if t == _word])\n",
    "            elif len(_word.split()) > 1:\n",
    "                type_count_dict[_type] += len(re.findall(_word, ' '.join(test_tokens)))\n",
    "\n",
    "    # If found any types, return them\n",
    "    if len(type_count_dict) > 0:\n",
    "        return list(set([_type for _type, _count in type_count_dict.items() if _count > 0]))\n",
    "\n",
    "    # If there were no type mentions at all, and the parent post couldn't be found, return this \n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(x):\n",
    "    try:\n",
    "        return datetime.utcfromtimestamp(int(x)).year\n",
    "    except:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(x):\n",
    "    try:\n",
    "        return datetime.utcfromtimestamp(int(x)).month\n",
    "    except:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(r):\n",
    "    if 'title' in r:\n",
    "        return lmw.process_string(str(r['title']), remove_short_words=False) + ' ' + lmw.process_string(str(r['selftext']), remove_short_words=False)\n",
    "    return lmw.process_string(str(r['selftext']), remove_short_words=False)\n",
    "\n",
    "def get_tokens_from_comment(r):\n",
    "    return lmw.process_string(str(r['body']), remove_short_words=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# **Process posts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load scraped posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94153"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df_list = []\n",
    "for _subdir, _dirs, _files in os.walk(scraped_directory_path + '/posts'):\n",
    "    for _file_name in _files:\n",
    "        if _file_name.endswith('.csv'):\n",
    "            posts_df_list.append(pd.read_csv(_subdir + '/' + _file_name))\n",
    "\n",
    "posts_df = pd.concat(posts_df_list)\n",
    "len(posts_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df['selftext'] = posts_df['selftext'].astype(str)\n",
    "posts_df['tokens_text'] = posts_df.apply(get_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alesse, altavera, alyacen, amethia, amethia lo, amethyst, apri, ashlyna, aubra, aviane, azurette, balziva, beyaz, blisovi, blisovi fe, camila, camrese, camrese lo, caziant, chateal, cryselle, cyclafem, cyclessa, dasetta, daysee, demulen, desogen, desogestrel, desogestrel ethinyl estradiol, emoquette, enpresse, enskyce, errin, estarylla, estrostep, estrostep fe, falmina, femcon, gedarel, generess, generess fe, gianvi, gildess, gildess fe, heather, introvale, isibloom, jolessa, jolivette, junel, junel fe, kariva, kelnor, kurvelo, larin, larin fe, larissia, leena, lessina, levlen, levonorgestrel, levonorgestrel ec, levora, linessa, lo loestrin fe, lo ovral, loestren, loestrin, loestrin fe, lolo, loloestrin, lomedia, loryna, loseasonique, low ogestrel, lutera, lybrel, lyza, marlissa, microgestin, microgestin fe, micronor, minastrin, minipill, mircette, mono linyah, mononessa, myzilra, natazia, necon, necon triphasic, nikki, nora be, nordette, norethindrone, norgestimate, norgestimate ethinyl estradiol, norgestrel, norgestrel ethiny estra, norinyl, nortrel, ocella, ogestrel, oral birth control, oral contracept, orsythia, ortho cept, ortho cyclen, ortho micronor, ortho novum, ortho novum triphasic, ortho tri cyclen, ortho tri cyclen lo, ovcon, pack, pill, pills, pimtrea, placebo, portia, previfem, quartette, quasense, reclipsen, safyral, seasonique, sharobel, sprintec, sronyx, syeda, tarina, tarina fe, taytulla, tilia, tilia fe, tri cyclen, tri estarylla, tri jordyna, tri legest fe, tri levlen, tri linyah, tri lo sprintec, tri norinyl, tri previfem, tri sprintec, tricyclen, trinessa, triphasil, trivora, velivet, vestura, vienva, viorele, vyfemla, yasmin, yaz, zarah, zenchent, zenchent fe, zovia'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_dict = defaultdict(int)\n",
    "\n",
    "for i, r in posts_df.iterrows():\n",
    "\n",
    "    test_tokens = r['tokens_text'].split()\n",
    "\n",
    "    # Count how many times each type appears in the text\n",
    "    for _word in type_keywords_dict['pill']:\n",
    "        if len(_word.split()) == 1:\n",
    "            word_count_dict[_word] += len([t for t in test_tokens if t == _word])\n",
    "        elif len(_word.split()) > 1:\n",
    "            word_count_dict[_word] += len(re.findall(_word, ' '.join(test_tokens)))\n",
    "\n",
    "found_words = []\n",
    "for _word, _count in sorted(word_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    if _count > 0:\n",
    "        found_words.append(_word)\n",
    "', '.join(sorted(found_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get birth control type from post text, dropping posts that don't have a type or that aren't in our three target types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df['text_type'] = posts_df.apply(get_all_types_from_post, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54507 \t 0.579 \t pill\n",
      "33827 \t 0.359 \t iud\n",
      "13543 \t 0.144 \t implant\n",
      "12267 \t 0.13 \t barrier\n",
      "6485 \t 0.069 \t shot\n",
      "5226 \t 0.056 \t emergency\n",
      "4884 \t 0.052 \t ring\n",
      "3045 \t 0.032 \t withdrawal\n",
      "2436 \t 0.026 \t patch\n",
      "878 \t 0.009 \t sterilization\n",
      "517 \t 0.005 \t periodic abstinence\n"
     ]
    }
   ],
   "source": [
    "type_count_dict = defaultdict(int)\n",
    "for i, r in posts_df.iterrows():\n",
    "    for _type in r['text_type']:\n",
    "        type_count_dict[_type] += 1\n",
    "\n",
    "for _type, _count in sorted(type_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', round(_count/float(len(posts_df.index)), 3), '\\t', _type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94153"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04638195277898739"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4367/94153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_type_dict = {str(r['id']): r['text_type'] for i, r in posts_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82041"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_target_types(types_list):\n",
    "    types_list = [_ for _ in types_list if _ in ['pill', 'iud', 'implant']]\n",
    "    if types_list:\n",
    "        return sorted(types_list)\n",
    "    return 'unknown'\n",
    "\n",
    "posts_df['text_type'] = posts_df['text_type'].apply(convert_to_target_types)\n",
    "posts_df = posts_df[posts_df['text_type'] != 'unknown']\n",
    "len(posts_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n",
      "Traceback (most recent call last):\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5231, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n",
      "TypeError: unhashable type: 'list'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[pill]                  38797\n",
       "[iud]                   19708\n",
       "[iud, pill]              9993\n",
       "[implant]                6250\n",
       "[implant, pill]          3167\n",
       "[implant, iud, pill]     2550\n",
       "[implant, iud]           1576\n",
       "Name: text_type, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df['text_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8110734655295104"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "76365/94153"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get year and month and remove comments whose years can't be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82041"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df['year'] = posts_df['created_utc'].apply(get_year)\n",
    "posts_df['month'] = posts_df['created_utc'].apply(get_month)\n",
    "posts_df = posts_df[(posts_df['year'] != 'Unknown') & (posts_df['year'] != 1970)]\n",
    "len(posts_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, r in posts_df[posts_df['text_type'] == 'implant'].sample(10).iterrows():\n",
    "#     print(r['title'])\n",
    "#     print()\n",
    "#     print(r['text'])\n",
    "#     print()\n",
    "#     print('============================================')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    26691\n",
       "2019    20736\n",
       "2018    12347\n",
       "2017     7450\n",
       "2016     4930\n",
       "2015     3880\n",
       "2014     2831\n",
       "2013     1955\n",
       "2012     1083\n",
       "2011      138\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove short posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_tokens(text):\n",
    "    if pd.isnull(text):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "posts_df['num_tokens'] = posts_df['selftext'].apply(get_num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81972"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The token length requirement also handles deleted comments, which are replaced with the single \"[deleted]\" token.\n",
    "posts_df = posts_df[(posts_df['num_tokens'] >= 3)]\n",
    "len(posts_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81596"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df = posts_df.drop_duplicates(subset='selftext')\n",
    "len(posts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary columns, rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = posts_df[['id', 'created_utc', 'selftext', 'title', 'year', 'month', 'url', 'link_flair_text', 'tokens_text', 'text_type']]\n",
    "posts_df = posts_df.rename(columns={'selftext': 'text'})\n",
    "posts_df['source'] = 'reddit-posts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove November-December 2020 to match WebMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    26434\n",
       "2019    20633\n",
       "2018    12294\n",
       "2017     7442\n",
       "2016     4928\n",
       "2015     3876\n",
       "2014     2825\n",
       "2013     1948\n",
       "2012     1079\n",
       "2011      137\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77231"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df = posts_df[~((posts_df['year'] == 2020) & (posts_df['month'].isin([11, 12])))]\n",
    "len(posts_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    22069\n",
       "2019    20633\n",
       "2018    12294\n",
       "2017     7442\n",
       "2016     4928\n",
       "2015     3876\n",
       "2014     2825\n",
       "2013     1948\n",
       "2012     1079\n",
       "2011      137\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77231"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n",
      "Traceback (most recent call last):\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5231, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n",
      "TypeError: unhashable type: 'list'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[pill]                  36492\n",
       "[iud]                   18482\n",
       "[iud, pill]              9444\n",
       "[implant]                5904\n",
       "[implant, pill]          2991\n",
       "[implant, iud, pill]     2431\n",
       "[implant, iud]           1487\n",
       "Name: text_type, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df['text_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    22069\n",
       "2019    20633\n",
       "2018    12294\n",
       "2017     7442\n",
       "2016     4928\n",
       "2015     3876\n",
       "2014     2825\n",
       "2013     1948\n",
       "2012     1079\n",
       "2011      137\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>tokens_text</th>\n",
       "      <th>text_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>iqi321</td>\n",
       "      <td>1599791816</td>\n",
       "      <td>I was able to get my IUD today! Going in I kne...</td>\n",
       "      <td>Paragard IUD insertion experience</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.reddit.com/r/birthcontrol/comments...</td>\n",
       "      <td>Experience</td>\n",
       "      <td>paragard iud insertion experience able get iud...</td>\n",
       "      <td>[iud]</td>\n",
       "      <td>reddit-posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>7wf0ii</td>\n",
       "      <td>1518197201</td>\n",
       "      <td>Wondering if anyone had had a simalar experien...</td>\n",
       "      <td>Iud strings missing</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/birthcontrol/comments...</td>\n",
       "      <td>Experience</td>\n",
       "      <td>iud strings missing wondering anyone simalar e...</td>\n",
       "      <td>[iud]</td>\n",
       "      <td>reddit-posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>g6f0hi</td>\n",
       "      <td>1587610541</td>\n",
       "      <td>Hi! \\n\\nI’m considering going off of the pill ...</td>\n",
       "      <td>Changes after going off birth control?!</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.reddit.com/r/birthcontrol/comments...</td>\n",
       "      <td>Experience</td>\n",
       "      <td>changes going birth control hi m considering g...</td>\n",
       "      <td>[iud, pill]</td>\n",
       "      <td>reddit-posts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id created_utc                                               text  \\\n",
       "1710  iqi321  1599791816  I was able to get my IUD today! Going in I kne...   \n",
       "612   7wf0ii  1518197201  Wondering if anyone had had a simalar experien...   \n",
       "578   g6f0hi  1587610541  Hi! \\n\\nI’m considering going off of the pill ...   \n",
       "\n",
       "                                        title  year  month  \\\n",
       "1710        Paragard IUD insertion experience  2020      9   \n",
       "612                       Iud strings missing  2018      2   \n",
       "578   Changes after going off birth control?!  2020      4   \n",
       "\n",
       "                                                    url link_flair_text  \\\n",
       "1710  https://www.reddit.com/r/birthcontrol/comments...      Experience   \n",
       "612   https://www.reddit.com/r/birthcontrol/comments...      Experience   \n",
       "578   https://www.reddit.com/r/birthcontrol/comments...      Experience   \n",
       "\n",
       "                                            tokens_text    text_type  \\\n",
       "1710  paragard iud insertion experience able get iud...        [iud]   \n",
       "612   iud strings missing wondering anyone simalar e...        [iud]   \n",
       "578   changes going birth control hi m considering g...  [iud, pill]   \n",
       "\n",
       "            source  \n",
       "1710  reddit-posts  \n",
       "612   reddit-posts  \n",
       "578   reddit-posts  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts_df.to_csv(data_directory_path + '/final-data/reddit_posts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Process comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the scraped comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492713"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df_list = []\n",
    "for _subdir, _dirs, _files in os.walk(scraped_directory_path + '/comments'):\n",
    "    for _file_name in _files:\n",
    "        if _file_name.endswith('.csv'):\n",
    "            comments_df_list.append(pd.read_csv(_subdir + '/' + _file_name))\n",
    "\n",
    "comments_df = pd.concat(comments_df_list)\n",
    "len(comments_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['body'] = comments_df['body'].astype(str)\n",
    "comments_df['tokens_text'] = comments_df.apply(get_tokens_from_comment, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace parent tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251584\n",
      "365373\n",
      "425784\n",
      "454244\n",
      "469090\n",
      "476854\n",
      "481292\n",
      "483858\n",
      "485462\n",
      "486484\n",
      "487195\n",
      "487683\n"
     ]
    }
   ],
   "source": [
    "comment_parent_dict = {}\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type == 't3':\n",
    "            comment_parent_dict[str(r['id'])] = _parent\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))\n",
    "\n",
    "for i, r in comments_df.iterrows():\n",
    "    if len(str(r['parent_id']).split('_')) > 1:\n",
    "        _type, _parent = str(r['parent_id']).split('_')\n",
    "        if _type != 't3' and _parent in comment_parent_dict:\n",
    "            comment_parent_dict[str(r['id'])] = comment_parent_dict[_parent]\n",
    "\n",
    "print(len(comment_parent_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the birth control type from either the comment or the parent post (drop if neither method works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i, r in comments_df[comments_df['text_type'] == 'unknown'].sample(10).iterrows():\n",
    "\n",
    "# # print(' '.join(r['body'].split()))\n",
    "\n",
    "# # test_tokens = str(r['tokens_text']).split()\n",
    "\n",
    "# test_tokens = 'Gotcha! Well in that case I say try out the Nexplanon. You also may be able to get your option through Planned Parenthood or Nurx. They may be able to supply you with enough to last you the entire year if you want to try a pill, ring, or patch. But since hormones are not an issue and if you still have insurance that will cover it, I say for for the Nexplanon. If that doesn\\'t work, try the other options I listed. I hope you find something that works for you!'\n",
    "# test_tokens = lmw.process_string(test_tokens).split()\n",
    "# print(test_tokens)\n",
    "\n",
    "# # Count how many times each type appears in the text\n",
    "# type_count_dict = defaultdict(int)\n",
    "# for _type, _keywords in type_keywords_dict.items():\n",
    "#     for _word in _keywords:\n",
    "#         if len(_word.split()) == 1:\n",
    "#             type_count_dict[_type] += len([t for t in test_tokens if t == _word])\n",
    "#         elif len(_word.split()) > 1:\n",
    "#             type_count_dict[_type] += len(re.findall(_word, ' '.join(test_tokens)))\n",
    "\n",
    "# print(type_count_dict)\n",
    "\n",
    "# # Get the maximum number of times any type appears in the text \n",
    "# max_count = max(type_count_dict.values())\n",
    "# if max_count != 0:\n",
    "#     max_keys = {k for k, v in type_count_dict.items() if v == max_count}\n",
    "#     print(random.sample(max_keys, 1)[0])\n",
    "\n",
    "# # If no assignment, then assign to parent post type\n",
    "# # elif len(str(r['parent_id']).split('_')) > 1:\n",
    "# #     print(r['parent_id'])\n",
    "# #     print(r['id'])\n",
    "# #     parent_id = str(r['parent_id']).split('_')[1] \n",
    "# #     if parent_id in post_type_dict:\n",
    "# #         print(post_type_dict[parent_id])\n",
    "\n",
    "# # If there were no type mentions at all, and the parent post couldn't be found, return this \n",
    "# print('unknown')\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['text_type'] = comments_df.apply(get_all_types_from_comment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post_type_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n8/40phkcv97hj6ltnvb_9y7njh0000gn/T/ipykernel_32966/1291572157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomments_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_parent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n8/40phkcv97hj6ltnvb_9y7njh0000gn/T/ipykernel_32966/461368404.py\u001b[0m in \u001b[0;36mget_parent_type\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_parent_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomment_parent_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomment_parent_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpost_type_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpost_type_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomment_parent_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'post_type_dict' is not defined"
     ]
    }
   ],
   "source": [
    "comments_df['parent_type'] = comments_df.apply(get_parent_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_count_dict = defaultdict(int)\n",
    "for i, r in comments_df.iterrows():\n",
    "    for _type in r['text_type']:\n",
    "        type_count_dict[_type] += 1\n",
    "\n",
    "for _type, _count in sorted(type_count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(_count, '\\t', round(_count/float(len(comments_df.index)), 3), '\\t', _type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown                230488\n",
       "pill                   100649\n",
       "iud                     87709\n",
       "implant                 23379\n",
       "barrier                 14735\n",
       "shot                    10344\n",
       "emergency                8321\n",
       "ring                     6836\n",
       "withdrawal               3343\n",
       "patch                    2887\n",
       "periodic abstinence      2070\n",
       "sterilization            1952\n",
       "Name: text_type, dtype: int64"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['text_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown                0.467794\n",
       "pill                   0.204275\n",
       "iud                    0.178012\n",
       "implant                0.047450\n",
       "barrier                0.029906\n",
       "shot                   0.020994\n",
       "emergency              0.016888\n",
       "ring                   0.013874\n",
       "withdrawal             0.006785\n",
       "patch                  0.005859\n",
       "periodic abstinence    0.004201\n",
       "sterilization          0.003962\n",
       "Name: text_type, dtype: float64"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['text_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pill                   163454\n",
       "iud                    152538\n",
       "unknown                 66614\n",
       "implant                 42055\n",
       "barrier                 21780\n",
       "shot                    15837\n",
       "ring                    10768\n",
       "emergency               10474\n",
       "patch                    4542\n",
       "withdrawal               1831\n",
       "sterilization            1569\n",
       "periodic abstinence      1251\n",
       "Name: parent_type, dtype: int64"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['parent_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pill                   0.331743\n",
       "iud                    0.309588\n",
       "unknown                0.135198\n",
       "implant                0.085354\n",
       "barrier                0.044204\n",
       "shot                   0.032142\n",
       "ring                   0.021855\n",
       "emergency              0.021258\n",
       "patch                  0.009218\n",
       "withdrawal             0.003716\n",
       "sterilization          0.003184\n",
       "periodic abstinence    0.002539\n",
       "Name: parent_type, dtype: float64"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['parent_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492713"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373237"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comments_df = comments_df[(comments_df['text_type'].isin(['pill', 'iud', 'implant'])) | ((comments_df['text_type'] == 'unknown') & (comments_df['parent_type'].isin(['pill', 'iud', 'implant'])))]\n",
    "\n",
    "def add_parent_type(r):\n",
    "    if r['text_type'] == 'unknown':\n",
    "        return r['parent_type']\n",
    "    return r['text_type']\n",
    "\n",
    "comments_df['text_type'] = comments_df.apply(add_parent_type, axis=1)\n",
    "comments_df = comments_df[comments_df['text_type'].isin(['pill', 'iud', 'implant'])]\n",
    "\n",
    "len(comments_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6278827633936997"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "309366/492713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, r in comments_df[comments_df['text_type'] == 'implant'].sample(10).iterrows():\n",
    "#     print(r['body'])\n",
    "#     print()\n",
    "#     print('============================================')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_type_dict = {r['id']: r['text_type'] for i, r in comments_df.iterrows()}\n",
    "pickle.dump(id_type_dict, open(data_directory_path + '/labeling/reddit_comments.id_type_dict.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the year and month and remove comments whose years cannot be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373237"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['year'] = comments_df['created_utc'].apply(get_year)\n",
    "comments_df['month'] = comments_df['created_utc'].apply(get_month)\n",
    "comments_df = comments_df[(comments_df['year'] != 'Unknown') & (comments_df['year'] != 1970)]\n",
    "len(comments_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    105482\n",
       "2019     86917\n",
       "2018     59785\n",
       "2017     41683\n",
       "2016     27269\n",
       "2015     21118\n",
       "2014     15477\n",
       "2013      9771\n",
       "2012      5254\n",
       "2011       481\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove comments by the OP, stickied comments, and comments where the user was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315370"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = comments_df[(comments_df['is_submitter']) != True & (comments_df['stickied'] == False) & (comments_df['user_removed'] != False)]\n",
    "len(comments_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove comments without a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315370"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = comments_df.dropna(subset=['created_utc'])\n",
    "len(comments_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove short comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_tokens(text):\n",
    "    if pd.isnull(text):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "comments_df['num_tokens'] = comments_df['body'].apply(get_num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302559"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The token length requirement also handles deleted comments, which are replaced with the single \"[deleted]\" token.\n",
    "comments_df = comments_df[(comments_df['num_tokens'] >= 3)]\n",
    "len(comments_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300567"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = comments_df.drop_duplicates(subset='body')\n",
    "len(comments_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all the unnecessary columns, rename columns, add source column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = comments_df[['id', 'parent_id', 'created_utc', 'body', 'tokens_text', 'text_type', 'year', 'month']]\n",
    "comments_df = comments_df.rename(columns={'body': 'text'})\n",
    "comments_df['source'] = 'reddit-comments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    76660\n",
       "2019    68726\n",
       "2018    44003\n",
       "2017    37097\n",
       "2016    26172\n",
       "2015    19919\n",
       "2014    14115\n",
       "2013     8740\n",
       "2012     4707\n",
       "2011      428\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove November-December 2020 to match WebMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    76660\n",
       "2019    68726\n",
       "2018    44003\n",
       "2017    37097\n",
       "2016    26172\n",
       "2015    19919\n",
       "2014    14115\n",
       "2013     8740\n",
       "2012     4707\n",
       "2011      428\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287279"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = comments_df[~((comments_df['year'] == 2020) & (comments_df['month'].isin([11, 12])))]\n",
    "len(comments_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019    68726\n",
       "2020    63372\n",
       "2018    44003\n",
       "2017    37097\n",
       "2016    26172\n",
       "2015    19919\n",
       "2014    14115\n",
       "2013     8740\n",
       "2012     4707\n",
       "2011      428\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287279"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens_text</th>\n",
       "      <th>text_type</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>do0l1wi</td>\n",
       "      <td>t3_74qoad</td>\n",
       "      <td>1507334645</td>\n",
       "      <td>An ultra sound or x-ray will see it as other p...</td>\n",
       "      <td>ultra sound x ray see people said gynecologica...</td>\n",
       "      <td>iud</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>reddit-comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>f7hqusl</td>\n",
       "      <td>t3_dw66ti</td>\n",
       "      <td>1573745851</td>\n",
       "      <td>I'm on Alesse and have been for several years....</td>\n",
       "      <td>m alesse several years experienced little naus...</td>\n",
       "      <td>pill</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>reddit-comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>coxavru</td>\n",
       "      <td>t1_coxaru7</td>\n",
       "      <td>1424911433</td>\n",
       "      <td>Your old doctor's office can give you your med...</td>\n",
       "      <td>old doctor office give medical records send ne...</td>\n",
       "      <td>pill</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>reddit-comments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   parent_id created_utc  \\\n",
       "3728  do0l1wi   t3_74qoad  1507334645   \n",
       "5031  f7hqusl   t3_dw66ti  1573745851   \n",
       "108   coxavru  t1_coxaru7  1424911433   \n",
       "\n",
       "                                                   text  \\\n",
       "3728  An ultra sound or x-ray will see it as other p...   \n",
       "5031  I'm on Alesse and have been for several years....   \n",
       "108   Your old doctor's office can give you your med...   \n",
       "\n",
       "                                            tokens_text text_type  year  \\\n",
       "3728  ultra sound x ray see people said gynecologica...       iud  2017   \n",
       "5031  m alesse several years experienced little naus...      pill  2019   \n",
       "108   old doctor office give medical records send ne...      pill  2015   \n",
       "\n",
       "      month           source  \n",
       "3728     10  reddit-comments  \n",
       "5031     11  reddit-comments  \n",
       "108       2  reddit-comments  "
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pill       127585\n",
       "iud        125158\n",
       "implant     34536\n",
       "Name: text_type, dtype: int64"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['text_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019    68726\n",
       "2020    63372\n",
       "2018    44003\n",
       "2017    37097\n",
       "2016    26172\n",
       "2015    19919\n",
       "2014    14115\n",
       "2013     8740\n",
       "2012     4707\n",
       "2011      428\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.to_csv(data_directory_path + '/final-data/reddit_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens_text</th>\n",
       "      <th>text_type</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>ewvrdye</td>\n",
       "      <td>t3_cq95wj</td>\n",
       "      <td>1565812355</td>\n",
       "      <td>I just had my first one done today. I got the ...</td>\n",
       "      <td>first one done today got mirena kids reference...</td>\n",
       "      <td>iud</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>reddit-comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>fixgg58</td>\n",
       "      <td>t1_fixduzi</td>\n",
       "      <td>1582819946</td>\n",
       "      <td>Yep!\\n\\nA bleeding can be considered a period ...</td>\n",
       "      <td>yep bleeding considered period part natural cy...</td>\n",
       "      <td>implant</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>reddit-comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11800</th>\n",
       "      <td>g3mc6ak</td>\n",
       "      <td>t1_g3mbu99</td>\n",
       "      <td>1598983859</td>\n",
       "      <td>I’d say after like 3 weeks of your missed peri...</td>\n",
       "      <td>d say like NUM weeks missed period taken pregn...</td>\n",
       "      <td>iud</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>reddit-comments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id   parent_id created_utc  \\\n",
       "5200   ewvrdye   t3_cq95wj  1565812355   \n",
       "330    fixgg58  t1_fixduzi  1582819946   \n",
       "11800  g3mc6ak  t1_g3mbu99  1598983859   \n",
       "\n",
       "                                                    text  \\\n",
       "5200   I just had my first one done today. I got the ...   \n",
       "330    Yep!\\n\\nA bleeding can be considered a period ...   \n",
       "11800  I’d say after like 3 weeks of your missed peri...   \n",
       "\n",
       "                                             tokens_text text_type  year  \\\n",
       "5200   first one done today got mirena kids reference...       iud  2019   \n",
       "330    yep bleeding considered period part natural cy...   implant  2020   \n",
       "11800  d say like NUM weeks missed period taken pregn...       iud  2020   \n",
       "\n",
       "       month           source  \n",
       "5200       8  reddit-comments  \n",
       "330        2  reddit-comments  \n",
       "11800      9  reddit-comments  "
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'parent_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'parent_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n8/40phkcv97hj6ltnvb_9y7njh0000gn/T/ipykernel_1805/2672921518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomments_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'unknown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Text Type:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parent Type:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'parent_type'"
     ]
    }
   ],
   "source": [
    "target_df = comments_df[comments_df['parent_type'] != 'unknown']\n",
    "for i, r in target_df[target_df['text_type'] != target_df['parent_type']].sample(10).iterrows():\n",
    "    print('Text Type:', r['text_type'])\n",
    "    print('Parent Type:', r['parent_type'])\n",
    "    print(' '.join(r['text'].split()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n8/40phkcv97hj6ltnvb_9y7njh0000gn/T/ipykernel_1805/335909620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomments_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'unknown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Text Type:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parent Type:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python3.8env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   5363\u001b[0m             )\n\u001b[1;32m   5364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5365\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5366\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "target_df = comments_df[comments_df['text_type'] == 'unknown']\n",
    "for i, r in target_df.sample(10).iterrows():\n",
    "    print('Text Type:', r['text_type'])\n",
    "    print('Parent Type:', r['parent_type'])\n",
    "    print(' '.join(r['text'].split()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88435282e7afd386f137f5bf71124f6ca50142be149f9ca18724b5a580de610c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('python3.7env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "3bf6718e1fb94d37e4dcdce4af31e71b15d9d634835b5761d954c77044e0e9ad"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import jsonlines\n",
    "import pandas as pd \n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_path   = '/Volumes/Passport-1/data/birth-control'\n",
    "output_directory_path = '/Volumes/Passport-1/output/birth-control'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_posts_df = pd.read_csv(data_directory_path + '/final-data/reddit_posts.csv')\n",
    "reddit_comments_df = pd.read_csv(data_directory_path + '/final-data/reddit_comments.csv')\n",
    "webmd_df = pd.read_csv(data_directory_path + '/final-data/webmd.csv')\n",
    "twitter_posts_df = pd.read_csv(data_directory_path + '/final-data/twitter_posts.csv')\n",
    "twitter_replies_df = pd.read_csv(data_directory_path + '/final-data/twitter_replies.csv')\n",
    "\n",
    "dataframes = [reddit_posts_df, reddit_comments_df, twitter_posts_df, twitter_replies_df, webmd_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1063672"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat(dataframes)\n",
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twitter-posts      499796\n",
       "reddit-comments    264912\n",
       "twitter-replies    211896\n",
       "reddit-posts        68958\n",
       "webmd-reviews       18110\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample data\n",
    "\n",
    "- same number of texts per source\n",
    "- same number of texts per method\n",
    "- same number of sentences per text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataframes = []\n",
    "for _df in dataframes:\n",
    "    sampled_dataframes.append(_df.groupby('text_type').sample(n=400, random_state=1))\n",
    "    \n",
    "sampled_df = pd.concat(sampled_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reddit-posts       1200\n",
       "reddit-comments    1200\n",
       "twitter-posts      1200\n",
       "twitter-replies    1200\n",
       "webmd-reviews      1200\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "implant    2000\n",
       "iud        2000\n",
       "pill       2000\n",
       "Name: text_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df['text_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Prodigy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dicts(df):\n",
    "    data_dicts = []\n",
    "    for i, r in df.iterrows():\n",
    "\n",
    "        _full_text = r['text']\n",
    "        _sentences = [s.text.strip() for s in nlp(r['text']).sents]\n",
    "\n",
    "        if 'title' in r and not pd.isnull(r['title']):\n",
    "            _sentences += [s.text for s in nlp(r['title']).sents]\n",
    "            _full_text = '[TITLE: ' + r['title'].strip() + '] \\n\\n' + r['text']\n",
    "\n",
    "        _sentences = [s for s in _sentences if len(s.split()) >= 3]\n",
    "\n",
    "        if len(_sentences) >= 1:\n",
    "            for _sentence in random.sample(_sentences, 1):\n",
    "                data_dicts.append({'text': _sentence,\n",
    "                                   'meta': {'ID': r['id'],\n",
    "                                            'Source': r['source'],\n",
    "                                            'Method': r['text_type'],\n",
    "                                            'Full Text': _full_text}})\n",
    "    return data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit-posts\n",
      "reddit-comments\n",
      "twitter-posts\n",
      "twitter-replies\n",
      "webmd-reviews\n"
     ]
    }
   ],
   "source": [
    "for _source in sampled_df['source'].unique():\n",
    "    print(_source)\n",
    "    _data_dicts = get_data_dicts(sampled_df[sampled_df['source'] == _source])\n",
    "    random.shuffle(_data_dicts)\n",
    "    with jsonlines.open(data_directory_path + '/labeling/label-sentences/sampled-sentences.prodigy.' + _source + '.jsonl', 'w') as writer:\n",
    "        writer.write_all(_data_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat to create test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pill       36921\n",
      "iud        24657\n",
      "implant     7380\n",
      "Name: text_type, dtype: int64\n",
      "iud        117631\n",
      "pill       117283\n",
      "implant     29998\n",
      "Name: text_type, dtype: int64\n",
      "pill       226762\n",
      "iud        217728\n",
      "implant     55306\n",
      "Name: text_type, dtype: int64\n",
      "iud        147680\n",
      "pill        39039\n",
      "implant     25177\n",
      "Name: text_type, dtype: int64\n",
      "pill       14873\n",
      "iud         2354\n",
      "implant      883\n",
      "Name: text_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for _df in dataframes:\n",
    "    print(_df['text_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataframes = []\n",
    "for _df in dataframes:\n",
    "    sampled_dataframes.append(_df.groupby('text_type').sample(n=800, random_state=1))\n",
    "    \n",
    "sampled_df = pd.concat(sampled_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reddit-posts       2400\n",
       "reddit-comments    2400\n",
       "twitter-posts      2400\n",
       "twitter-replies    2400\n",
       "webmd-reviews      2400\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit-posts\n",
      "reddit-comments\n",
      "twitter-posts\n",
      "twitter-replies\n",
      "webmd-reviews\n"
     ]
    }
   ],
   "source": [
    "test_dicts = []\n",
    "for _source in sampled_df['source'].unique():\n",
    "    print(_source)\n",
    "    test_dicts += get_data_dicts(sampled_df[sampled_df['source'] == _source])\n",
    "test_df = pd.DataFrame(test_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11993"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(data_directory_path + '/labeling/label-sentences/sampled-sentences.test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88435282e7afd386f137f5bf71124f6ca50142be149f9ca18724b5a580de610c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python3.8env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
